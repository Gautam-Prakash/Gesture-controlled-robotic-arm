{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e569d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2023-04-11 17:18:37.927308: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['okay', 'peace', 'thumbs up', 'thumbs down', 'call me', 'stop', 'rock', 'live long', 'fist', 'smile']\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "rock\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "fist\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "fist\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "fist\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "fist\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "fist\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "fist\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "\n",
    "\n",
    "# initialize mediapipe\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "# Load the gesture recognizer model\n",
    "model = load_model('mp_hand_gesture')\n",
    "\n",
    "# Load class names\n",
    "f = open('gesture.names', 'r')\n",
    "classNames = f.read().split('\\n')\n",
    "f.close()\n",
    "print(classNames)\n",
    "\n",
    "# Create a VideoCapture object to capture frames from the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize the MediaPipe Hand model\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Initialize the drawing module\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Define a function to run the hand gesture detection model\n",
    "def detect_gestures():\n",
    "    while True:\n",
    "        # Read each frame from the webcam\n",
    "        _, frame = cap.read()\n",
    "\n",
    "        x, y, c = frame.shape\n",
    "\n",
    "        # Flip the frame horizontally\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Get hand landmark prediction\n",
    "        result = hands.process(framergb)\n",
    "\n",
    "        # print(result)\n",
    "    \n",
    "        className = ''\n",
    "\n",
    "        # post process the result\n",
    "        if result.multi_hand_landmarks:\n",
    "            landmarks = []\n",
    "            for handslms in result.multi_hand_landmarks:\n",
    "                for lm in handslms.landmark:\n",
    "                    # print(id, lm)\n",
    "                    lmx = int(lm.x * x)\n",
    "                    lmy = int(lm.y * y)\n",
    "\n",
    "                    landmarks.append([lmx, lmy])\n",
    "\n",
    "                # Drawing landmarks on frames\n",
    "                mpDraw.draw_landmarks(frame, handslms, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Predict gesture\n",
    "                prediction = model.predict([landmarks])\n",
    "                # print(prediction)\n",
    "                classID = np.argmax(prediction)\n",
    "                className = classNames[classID]\n",
    "                print(className)\n",
    "#                 arduino.write(classID)\n",
    "#                 time.sleep(0.05)\n",
    "\n",
    "        # show the prediction on the frame\n",
    "        cv2.putText(frame, className, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Show the final output\n",
    "        cv2.imshow(\"Output\", frame) \n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    # release the webcam and destroy all active windows\n",
    "    cap.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Define a function to start the hand gesture detection when the user clicks a button\n",
    "def start_detection():\n",
    "    detect_gestures()\n",
    "\n",
    "# Create a window using Tkinter\n",
    "root = tk.Tk()\n",
    "root.title(\"Hand Gesture Detection\")\n",
    "\n",
    "# Create a button labeled \"Start\" and bind it to the start_detection function\n",
    "start_button = tk.Button(root, text=\"Start\", command=start_detection)\n",
    "start_button.pack(pady=20)\n",
    "\n",
    "# Run the main event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a756d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture a frame from the camera\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        # Convert the frame to RGB and process it with the MediaPipe Hand model\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(frame)\n",
    "\n",
    "        # Draw the hand landmarks and connections on the frame\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        # Display the frame in a window\n",
    "        cv2.imshow('Hand Gestures', frame)\n",
    "\n",
    "        # Break the loop if the user presses the 'q' key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the VideoCapture object and close the window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff802b9",
   "metadata": {},
   "source": [
    "# Works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b74644c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2023-04-11 17:24:05.767861: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['okay', 'peace', 'thumbs up', 'thumbs down', 'call me', 'stop', 'rock', 'live long', 'fist', 'smile']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 17:24:22.985 python[19155:1288321] IMKClient Stall detected, *please Report* your user scenario attaching a spindump (or sysdiagnose) that captures the problem - (imkxpc_bundleIdentifierWithReply:) block performed very slowly (3.08 secs).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n",
      "rock\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "peace\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "peace\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "peace\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "peace\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "peace\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "peace\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "peace\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "fist\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "fist\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "fist\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "\n",
    "\n",
    "# initialize mediapipe\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "# Load the gesture recognizer model\n",
    "model = load_model('mp_hand_gesture')\n",
    "\n",
    "# Load class names\n",
    "f = open('gesture.names', 'r')\n",
    "classNames = f.read().split('\\n')\n",
    "f.close()\n",
    "print(classNames)\n",
    "\n",
    "# Create a VideoCapture object to capture frames from the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize the MediaPipe Hand model\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Initialize the drawing module\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Define a function to run the hand gesture detection model\n",
    "def detect_gestures():\n",
    "    while True:\n",
    "        # Read each frame from the webcam\n",
    "        _, frame = cap.read()\n",
    "\n",
    "        x, y, c = frame.shape\n",
    "\n",
    "        # Flip the frame horizontally\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Get hand landmark prediction\n",
    "        result = hands.process(framergb)\n",
    "\n",
    "        # print(result)\n",
    "    \n",
    "        className = ''\n",
    "\n",
    "        # post process the result\n",
    "        if result.multi_hand_landmarks:\n",
    "            landmarks = []\n",
    "            for handslms in result.multi_hand_landmarks:\n",
    "                for lm in handslms.landmark:\n",
    "                    # print(id, lm)\n",
    "                    lmx = int(lm.x * x)\n",
    "                    lmy = int(lm.y * y)\n",
    "\n",
    "                    landmarks.append([lmx, lmy])\n",
    "\n",
    "                # Drawing landmarks on frames\n",
    "                mpDraw.draw_landmarks(frame, handslms, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Predict gesture\n",
    "                prediction = model.predict([landmarks])\n",
    "                # print(prediction)\n",
    "                classID = np.argmax(prediction)\n",
    "                className = classNames[classID]\n",
    "                print(className)\n",
    "#                 arduino.write(classID)\n",
    "#                 time.sleep(0.05)\n",
    "\n",
    "        # show the prediction on the frame\n",
    "        cv2.putText(frame, className, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Show the final output\n",
    "        cv2.imshow(\"Output\", frame) \n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    # release the webcam and destroy all active windows\n",
    "    cap.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Define a function to start the hand gesture detection when the user clicks a button\n",
    "def start_detection():\n",
    "    detect_gestures()\n",
    "\n",
    "# Create main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Hand Gesture Detection\")\n",
    "root.geometry(\"300x200\")\n",
    "\n",
    "# Create label for messages\n",
    "label = tk.Label(root, text=\"Click the button to detect hand gesture\", wraplength=250)\n",
    "label.pack(pady=20)\n",
    "\n",
    "# Create button for hand gesture detection\n",
    "button = tk.Button(root, text=\"Detect Hand Gesture\", command=detect_gestures)\n",
    "button.pack(pady=10)\n",
    "\n",
    "# Center the button in the window\n",
    "root.update_idletasks()\n",
    "button_width = button.winfo_width()\n",
    "button_height = button.winfo_height()\n",
    "screen_width = root.winfo_screenwidth()\n",
    "screen_height = root.winfo_screenheight()\n",
    "x = (screen_width // 2) - (button_width // 2)\n",
    "y = (screen_height // 2) - (button_height // 2)\n",
    "root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "# Start the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2be292b",
   "metadata": {},
   "source": [
    "# Adding some UI features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d527cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['okay', 'peace', 'thumbs up', 'thumbs down', 'call me', 'stop', 'rock', 'live long', 'fist', 'smile']\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "fist\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "live long\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "rock\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "call me\n",
      "1/1 [==============================] - 0s 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/env_tensorflow/lib/python3.9/tkinter/__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"/var/folders/ct/83j70b6n0xn__16hfxpffk4m0000gn/T/ipykernel_34612/2715090866.py\", line 73, in detect_gestures\n",
      "    className = classNames[classID]\n",
      "IndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "from serial import Serial\n",
    "\n",
    "arduino = Serial(port='/dev/tty.usbserial-A50285BI', baudrate=9600, timeout=.1)\n",
    "\n",
    "# initialize mediapipe\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "# Load the gesture recognizer model\n",
    "model = load_model('mp_hand_gesture')\n",
    "\n",
    "# Load class names\n",
    "f = open('gesture.names', 'r')\n",
    "classNames = f.read().split('\\n')\n",
    "f.close()\n",
    "print(classNames)\n",
    "\n",
    "# Create a VideoCapture object to capture frames from the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize the MediaPipe Hand model\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Initialize the drawing module\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Define a function to run the hand gesture detection model\n",
    "def detect_gestures():\n",
    "    while True:\n",
    "        # Read each frame from the webcam\n",
    "        _, frame = cap.read()\n",
    "\n",
    "        x, y, c = frame.shape\n",
    "\n",
    "        # Flip the frame horizontally\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Get hand landmark prediction\n",
    "        result = hands.process(framergb)\n",
    "\n",
    "        # print(result)\n",
    "    \n",
    "        className = ''\n",
    "\n",
    "        # post process the result\n",
    "        if result.multi_hand_landmarks:\n",
    "            landmarks = []\n",
    "            for handslms in result.multi_hand_landmarks:\n",
    "                for lm in handslms.landmark:\n",
    "                    # print(id, lm)\n",
    "                    lmx = int(lm.x * x)\n",
    "                    lmy = int(lm.y * y)\n",
    "\n",
    "                    landmarks.append([lmx, lmy])\n",
    "\n",
    "                # Drawing landmarks on frames\n",
    "                mpDraw.draw_landmarks(frame, handslms, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Predict gesture\n",
    "                prediction = model.predict([landmarks])\n",
    "                # print(prediction)\n",
    "                classID = np.argmax(prediction)\n",
    "                className = classNames[classID]\n",
    "                print(className)\n",
    "                arduino.write(classID)\n",
    "\n",
    "        # show the prediction on the frame\n",
    "        cv2.putText(frame, className, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Show the final output\n",
    "        cv2.imshow(\"Output\", frame) \n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    # release the webcam and destroy all active windows\n",
    "    cap.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Define a function to start the hand gesture detection when the user clicks a button\n",
    "def start_detection():\n",
    "    detect_gestures()\n",
    "\n",
    "# Create main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Hand Gesture Detection\")\n",
    "root.geometry(\"500x300\")\n",
    "\n",
    "# Create label for messages\n",
    "label = tk.Label(root, text=\"Click the button to detect hand gesture | Click Q to stop\", wraplength=250)\n",
    "label.pack(pady=20)\n",
    "\n",
    "# Create button for hand gesture detection\n",
    "button = tk.Button(root, text=\"Detect Hand Gesture\", command=detect_gestures)\n",
    "button.pack(pady=10)\n",
    "\n",
    "# Center the button in the window\n",
    "root.update_idletasks()\n",
    "button_width = button.winfo_width()\n",
    "button_height = button.winfo_height()\n",
    "screen_width = root.winfo_screenwidth()\n",
    "screen_height = root.winfo_screenheight()\n",
    "x = (screen_width // 2) - (button_width // 2)\n",
    "y = (screen_height // 2) - (button_height // 2)\n",
    "root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "# Set window icon\n",
    "root.iconbitmap('icon.ico') # Replace 'icon.ico' with your icon file path\n",
    "\n",
    "# Add tooltip to the button\n",
    "button_tooltip = \"Click to detect hand gesture\"\n",
    "button.bind('<Enter>', lambda event: label.config(text=button_tooltip))\n",
    "button.bind('<Leave>', lambda event: label.config(text=\"Click the button to detect hand gesture\"))\n",
    "\n",
    "# Add shortcut key for the button\n",
    "root.bind('<Return>', lambda event: detect_gestures())\n",
    "\n",
    "# Start the Tkinter event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60be115",
   "metadata": {},
   "source": [
    "# UI testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf41a283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2023-04-13 12:08:57.013559: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['okay', 'peace', 'thumbs up', 'thumbs down', 'call me', 'stop', 'rock', 'live long', 'fist', 'smile']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(classNames)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Create a VideoCapture object to capture frames from the camera\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVideoCapture\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Initialize the MediaPipe Hand model\u001b[39;00m\n\u001b[1;32m     28\u001b[0m mp_hands \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39msolutions\u001b[38;5;241m.\u001b[39mhands\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "\n",
    "\n",
    "# initialize mediapipe\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "# Load the gesture recognizer model\n",
    "model = load_model('mp_hand_gesture')\n",
    "\n",
    "# Load class names\n",
    "f = open('gesture.names', 'r')\n",
    "classNames = f.read().split('\\n')\n",
    "f.close()\n",
    "print(classNames)\n",
    "\n",
    "# Create a VideoCapture object to capture frames from the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize the MediaPipe Hand model\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Initialize the drawing module\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Define a function to run the hand gesture detection model\n",
    "def detect_gestures():\n",
    "    label.config(text=\"Hand gesture system activated\")\n",
    "    while True:\n",
    "        # Read each frame from the webcam\n",
    "        _, frame = cap.read()\n",
    "\n",
    "        x, y, c = frame.shape\n",
    "\n",
    "        # Flip the frame horizontally\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Get hand landmark prediction\n",
    "        result = hands.process(framergb)\n",
    "\n",
    "        # print(result)\n",
    "    \n",
    "        className = ''\n",
    "\n",
    "        # post process the result\n",
    "        if result.multi_hand_landmarks:\n",
    "            landmarks = []\n",
    "            for handslms in result.multi_hand_landmarks:\n",
    "                for lm in handslms.landmark:\n",
    "                    # print(id, lm)\n",
    "                    lmx = int(lm.x * x)\n",
    "                    lmy = int(lm.y * y)\n",
    "\n",
    "                    landmarks.append([lmx, lmy])\n",
    "\n",
    "                # Drawing landmarks on frames\n",
    "                mpDraw.draw_landmarks(frame, handslms, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Predict gesture\n",
    "                prediction = model.predict([landmarks])\n",
    "                # print(prediction)\n",
    "                classID = np.argmax(prediction)\n",
    "                className = classNames[classID]\n",
    "                print(className)\n",
    "\n",
    "        # show the prediction on the frame\n",
    "        cv2.putText(frame, className, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Show the final output\n",
    "        cv2.imshow(\"Output\", frame) \n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    # release the webcam and destroy all active windows\n",
    "    cap.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Define a function to start the hand gesture detection when the user clicks a button\n",
    "def start_detection():\n",
    "    detect_gestures()\n",
    "\n",
    "# Create main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Hand Gesture Detection\")\n",
    "root.geometry(\"500x300\")\n",
    "\n",
    "label = tk.Label(root, text=\"Hand gesture detection system not yet started\", font=(\"Helvetica\", 14), fg=\"black\")\n",
    "label.pack(pady=20)\n",
    "\n",
    "# Create label for messages\n",
    "label = tk.Label(root, text=\"Click the button to detect hand gesture | Click Q to stop detection\", wraplength=250, font=(\"Helvetica\", 12), fg=\"black\")\n",
    "label.pack(pady=20)\n",
    "\n",
    "# Create button for hand gesture detection\n",
    "button = tk.Button(root, text=\"Detect Hand Gesture\", command=detect_gestures, font=(\"Helvetica\", 14), bg=\"#388E3C\", fg=\"white\", activebackground=\"#2E7D32\", activeforeground=\"white\", relief=\"raised\")\n",
    "button.pack(pady=10)\n",
    "\n",
    "# Set button text color to contrast with the background color\n",
    "button.config(highlightthickness=0)\n",
    "button.config(highlightbackground=button.cget('bg'))\n",
    "button.config(highlightcolor=button.cget('bg'))\n",
    "\n",
    "# Center the button in the window\n",
    "root.update_idletasks()\n",
    "button_width = button.winfo_width()\n",
    "button_height = button.winfo_height()\n",
    "screen_width = root.winfo_screenwidth()\n",
    "screen_height = root.winfo_screenheight()\n",
    "x = (screen_width // 2) - (button_width // 2)\n",
    "y = (screen_height // 2) - (button_height // 2)\n",
    "root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "# Set window icon\n",
    "root.iconbitmap('icon.ico') # Replace 'icon.ico' with your icon file path\n",
    "\n",
    "# Add tooltip to the button\n",
    "button_tooltip = \"Click to detect hand gesture\"\n",
    "button.bind('<Enter>', lambda event: label.config(text=button_tooltip))\n",
    "button.bind('<Leave>', lambda event: label.config(text=\"Click the button to detect hand gesture\"))\n",
    "\n",
    "# Add shortcut key for the button\n",
    "root.bind('<Return>', lambda event: detect_gestures())\n",
    "\n",
    "# Configure window background color\n",
    "root.configure(bg=\"#F0F0F0\")\n",
    "\n",
    "# Start the Tkinter event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7fb1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52b7d22e",
   "metadata": {},
   "source": [
    "# Usablilty testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08ee6e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyqt5\n",
      "  Downloading PyQt5-5.15.9-cp37-abi3-macosx_10_13_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting PyQt5-sip<13,>=12.11\n",
      "  Downloading PyQt5_sip-12.12.0-cp39-cp39-macosx_10_9_universal2.whl (142 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting PyQt5-Qt5>=5.15.2\n",
      "  Downloading PyQt5_Qt5-5.15.2-py3-none-macosx_10_13_intel.whl (40.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyQt5-Qt5, PyQt5-sip, pyqt5\n",
      "Successfully installed PyQt5-Qt5-5.15.2 PyQt5-sip-12.12.0 pyqt5-5.15.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyqt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fe35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QLabel, QPushButton\n",
    "import tkinter as tk\n",
    "\n",
    "# Create main window\n",
    "class HandGestureDetectionApp(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super(HandGestureDetectionApp, self).__init__()\n",
    "        self.setWindowTitle(\"Hand Gesture Detection\")\n",
    "        self.setGeometry(100, 100, 500, 300)\n",
    "\n",
    "        # Add label for messages\n",
    "        self.label = QLabel(\"Hand gesture detection system not yet started\", self)\n",
    "        self.label.setGeometry(50, 50, 400, 20)\n",
    "\n",
    "        # Add button for hand gesture detection\n",
    "        self.button = QPushButton(\"Detect Hand Gesture\", self)\n",
    "        self.button.setGeometry(50, 100, 400, 40)\n",
    "        self.button.clicked.connect(self.detect_gestures)\n",
    "\n",
    "    def detect_gestures(self):\n",
    "        # Perform usability testing action\n",
    "        root = tk.Tk()\n",
    "        print(\"Performing usability testing: Hand gesture detection initiated\")\n",
    "        # Simulate button click\n",
    "        print(\"Button clicked: Detect Hand Gesture\")\n",
    "\n",
    "        # Simulate keyboard input\n",
    "        print(\"Pressing Q key to stop detection\")\n",
    "\n",
    "        # Simulate window resizing\n",
    "        print(\"Resizing window to 600x400\")\n",
    "        root.geometry(\"600x400\")\n",
    "\n",
    "        # Simulate tooltip display\n",
    "        print(\"Hovering over button to display tooltip\")\n",
    "\n",
    "        # Update label text\n",
    "        label.config(text=\"Hand gesture detection in progress...\")\n",
    "        print(\"Updating label text to 'Hand gesture detection in progress...'\")\n",
    "\n",
    "        # Simulate error handling\n",
    "        print(\"Simulating error: Invalid input detected\")\n",
    "        label.config(text=\"Error: Invalid input detected\", fg=\"red\")\n",
    "        print(\"Updating label text to 'Error: Invalid input detected' with red color\")\n",
    "\n",
    "        # Simulate navigation\n",
    "        print(\"Simulating navigation: Closing application\")\n",
    "        root.destroy()\n",
    "\n",
    "        # Bind button command to detect_gestures() function\n",
    "        button = tk.Button(root, text=\"Detect Hand Gesture\", command=detect_gestures)\n",
    "\n",
    "# Create Qt application\n",
    "app = QApplication(sys.argv)\n",
    "\n",
    "# Create instance of HandGestureDetectionApp\n",
    "window = HandGestureDetectionApp()\n",
    "window.show()\n",
    "\n",
    "# Run the event loop\n",
    "sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbdd5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e75d9997",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detect_gestures' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m label\u001b[38;5;241m.\u001b[39mpack(pady\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Create button for hand gesture detection\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m button \u001b[38;5;241m=\u001b[39m tk\u001b[38;5;241m.\u001b[39mButton(root, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetect Hand Gesture\u001b[39m\u001b[38;5;124m\"\u001b[39m, command\u001b[38;5;241m=\u001b[39m\u001b[43mdetect_gestures\u001b[49m)\n\u001b[1;32m     19\u001b[0m button\u001b[38;5;241m.\u001b[39mpack(pady\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Function to perform hand gesture detection\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'detect_gestures' is not defined"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "import unittest\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Hand Gesture Detection\")\n",
    "root.geometry(\"500x300\")\n",
    "\n",
    "label = tk.Label(root, text=\"Hand gesture detection system not yet started\")\n",
    "label.pack(pady=20)\n",
    "\n",
    "# Create label for messages\n",
    "label = tk.Label(root, text=\"Click the button to detect hand gesture | Click Q to stop detection\", wraplength=250)\n",
    "label.pack(pady=20)\n",
    "\n",
    "# Create button for hand gesture detection\n",
    "button = tk.Button(root, text=\"Detect Hand Gesture\", command=detect_gestures)\n",
    "button.pack(pady=10)\n",
    "\n",
    "# Function to perform hand gesture detection\n",
    "def detect_gestures():\n",
    "    # Placeholder for actual implementation\n",
    "    #pass\n",
    "    #label.config(text=\"Hand gesture system activated\")\n",
    "    while True:\n",
    "        # Read each frame from the webcam\n",
    "        _, frame = cap.read()\n",
    "\n",
    "        x, y, c = frame.shape\n",
    "\n",
    "        # Flip the frame horizontally\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Get hand landmark prediction\n",
    "        result = hands.process(framergb)\n",
    "\n",
    "        # print(result)\n",
    "    \n",
    "        className = ''\n",
    "\n",
    "        # post process the result\n",
    "        if result.multi_hand_landmarks:\n",
    "            landmarks = []\n",
    "            for handslms in result.multi_hand_landmarks:\n",
    "                for lm in handslms.landmark:\n",
    "                    # print(id, lm)\n",
    "                    lmx = int(lm.x * x)\n",
    "                    lmy = int(lm.y * y)\n",
    "\n",
    "                    landmarks.append([lmx, lmy])\n",
    "\n",
    "                # Drawing landmarks on frames\n",
    "                mpDraw.draw_landmarks(frame, handslms, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Predict gesture\n",
    "                prediction = model.predict([landmarks])\n",
    "                # print(prediction)\n",
    "                classID = np.argmax(prediction)\n",
    "                className = classNames[classID]\n",
    "                print(className)\n",
    "\n",
    "        # show the prediction on the frame\n",
    "        cv2.putText(frame, className, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Show the final output\n",
    "        cv2.imshow(\"Output\", frame) \n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    # release the webcam and destroy all active windows\n",
    "    cap.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "# Create a subclass of unittest.TestCase for usability tests\n",
    "class UsabilityTests(unittest.TestCase):\n",
    "    def test_button_visibility(self):\n",
    "        # Test if the button is visible\n",
    "        self.assertTrue(button.winfo_viewable())\n",
    "\n",
    "    def test_label_text(self):\n",
    "        # Test if the label text is correct\n",
    "        self.assertEqual(label.cget(\"text\"), \"Click the button to detect hand gesture | Click Q to stop detection\")\n",
    "\n",
    "    def test_label_wrap_length(self):\n",
    "        # Test if the label wrap length is as expected\n",
    "        self.assertEqual(label.cget(\"wraplength\"), 250)\n",
    "\n",
    "    def test_label_font(self):\n",
    "        # Test if the label font is as expected\n",
    "        self.assertEqual(label.cget(\"font\"), \"TkDefaultFont\")\n",
    "\n",
    "    def test_button_command(self):\n",
    "        # Test if the button command is set to detect_gestures function\n",
    "        self.assertEqual(button[\"command\"], detect_gestures)\n",
    "\n",
    "    # Add more usability tests as needed\n",
    "\n",
    "# Create a TestSuite with the usability tests\n",
    "usability_test_suite = unittest.TestSuite()\n",
    "usability_test_suite.addTest(UsabilityTests(\"test_button_visibility\"))\n",
    "usability_test_suite.addTest(UsabilityTests(\"test_label_text\"))\n",
    "usability_test_suite.addTest(UsabilityTests(\"test_label_wrap_length\"))\n",
    "usability_test_suite.addTest(UsabilityTests(\"test_label_font\"))\n",
    "usability_test_suite.addTest(UsabilityTests(\"test_button_command\"))\n",
    "# Add more usability tests as needed\n",
    "\n",
    "# Run the usability tests and get the test results\n",
    "usability_test_runner = unittest.TextTestRunner()\n",
    "usability_test_results = usability_test_runner.run(usability_test_suite)\n",
    "\n",
    "# Extract test results\n",
    "num_tests = usability_test_results.testsRun\n",
    "num_failures = len(usability_test_results.failures)\n",
    "num_errors = len(usability_test_results.errors)\n",
    "num_passed = num_tests - num_failures - num_errors\n",
    "\n",
    "# Plot the test results in a bar graph\n",
    "test_labels = ['Passed', 'Failures', 'Errors']\n",
    "test_counts = [num_passed, num_failures, num_errors]\n",
    "\n",
    "plt.bar(test_labels, test_counts)\n",
    "plt.xlabel('Test Results')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Usability Test Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f36d330",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m window\n\u001b[0;32m----> 6\u001b[0m window \u001b[38;5;241m=\u001b[39m \u001b[43mTk\u001b[49m()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Function to perform hand gesture detection\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_gestures\u001b[39m():\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Placeholder for actual implementation\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m#pass\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#label.config(text=\"Hand gesture system activated\")\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Tk' is not defined"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "import unittest\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create main window\n",
    "global window\n",
    "root = tk.Tk()\n",
    "root.title(\"Hand Gesture Detection\")\n",
    "root.geometry(\"500x300\")\n",
    "\n",
    "label = tk.Label(root, text=\"Hand gesture detection system not yet started\")\n",
    "label.pack(pady=20)\n",
    "\n",
    "# Create label for messages\n",
    "label = tk.Label(root, text=\"Click the button to detect hand gesture | Click Q to stop detection\", wraplength=250)\n",
    "label.pack(pady=20)\n",
    "\n",
    "# Create button for hand gesture detection\n",
    "button = tk.Button(root, text=\"Detect Hand Gesture\", command=detect_gestures)\n",
    "button.pack(pady=10)\n",
    "\n",
    "# Add the button widget to the window and specify grid options\n",
    "button.pack(padx=10, pady=10)\n",
    "\n",
    "# Start the tkinter event loop\n",
    "window.mainloop()\n",
    "\n",
    "# Function to perform hand gesture detection\n",
    "def detect_gestures():\n",
    "    # Placeholder for actual implementation\n",
    "    #pass\n",
    "    #label.config(text=\"Hand gesture system activated\")\n",
    "    while True:\n",
    "        # Read each frame from the webcam\n",
    "        _, frame = cap.read()\n",
    "\n",
    "        x, y, c = frame.shape\n",
    "\n",
    "        # Flip the frame horizontally\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Get hand landmark prediction\n",
    "        result = hands.process(framergb)\n",
    "\n",
    "        # print(result)\n",
    "    \n",
    "        className = ''\n",
    "\n",
    "        # post process the result\n",
    "        if result.multi_hand_landmarks:\n",
    "            landmarks = []\n",
    "            for handslms in result.multi_hand_landmarks:\n",
    "                for lm in handslms.landmark:\n",
    "                    # print(id, lm)\n",
    "                    lmx = int(lm.x * x)\n",
    "                    lmy = int(lm.y * y)\n",
    "\n",
    "                    landmarks.append([lmx, lmy])\n",
    "\n",
    "                # Drawing landmarks on frames\n",
    "                mpDraw.draw_landmarks(frame, handslms, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Predict gesture\n",
    "                prediction = model.predict([landmarks])\n",
    "                # print(prediction)\n",
    "                classID = np.argmax(prediction)\n",
    "                className = classNames[classID]\n",
    "                print(className)\n",
    "\n",
    "        # show the prediction on the frame\n",
    "        cv2.putText(frame, className, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Show the final output\n",
    "        cv2.imshow(\"Output\", frame) \n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    # release the webcam and destroy all active windows\n",
    "    cap.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "# Create a subclass of unittest.TestCase for usability tests\n",
    "class UsabilityTests(unittest.TestCase):\n",
    "    def test_button_visibility(self):\n",
    "        # Test if the button is visible\n",
    "        self.assertTrue(button.winfo_viewable())\n",
    "\n",
    "    def test_label_text(self):\n",
    "        # Test if the label text is correct\n",
    "        self.assertEqual(label.cget(\"text\"), \"Click the button to detect hand gesture | Click Q to stop detection\")\n",
    "\n",
    "    def test_label_wrap_length(self):\n",
    "        # Test if the label wrap length is as expected\n",
    "        self.assertEqual(label.cget(\"wraplength\"), 250)\n",
    "\n",
    "    def test_label_font(self):\n",
    "        # Test if the label font is as expected\n",
    "        self.assertEqual(label.cget(\"font\"), \"TkDefaultFont\")\n",
    "\n",
    "    def test_button_command(self):\n",
    "        # Test if the button command is set to detect_gestures function\n",
    "        self.assertEqual(button['command'], detect_gestures)\n",
    "\n",
    "    # Add more usability tests as needed\n",
    "\n",
    "# Create a TestSuite with the usability tests\n",
    "usability_test_suite = unittest.TestSuite()\n",
    "usability_test_suite.addTest(UsabilityTests(\"test_button_visibility\"))\n",
    "usability_test_suite.addTest(UsabilityTests(\"test_label_text\"))\n",
    "usability_test_suite.addTest(UsabilityTests(\"test_label_wrap_length\"))\n",
    "usability_test_suite.addTest(UsabilityTests(\"test_label_font\"))\n",
    "usability_test_suite.addTest(UsabilityTests(\"test_button_command\"))\n",
    "# Add more usability tests as needed\n",
    "\n",
    "# Run the usability tests and get the test results\n",
    "usability_test_runner = unittest.TextTestRunner()\n",
    "usability_test_results = usability_test_runner.run(usability_test_suite)\n",
    "\n",
    "# Extract test results\n",
    "num_tests = usability_test_results.testsRun\n",
    "num_failures = len(usability_test_results.failures)\n",
    "num_errors = len(usability_test_results.errors)\n",
    "num_passed = num_tests - num_failures - num_errors\n",
    "\n",
    "# Plot the test results in a bar graph\n",
    "test_labels = ['Passed', 'Failures', 'Errors']\n",
    "test_counts = [num_passed, num_failures, num_errors]\n",
    "\n",
    "plt.bar(test_labels, test_counts)\n",
    "plt.xlabel('Test Results')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Usability Test Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f04e8d7",
   "metadata": {},
   "source": [
    "# Interface testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a514abc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: /Users/gautamprakash/Library/Jupyter/runtime/kernel-4ca4eb32-0594-4ea0-9725-3de00e7fcb24 (unittest.loader._FailedTest)\n",
      "----------------------------------------------------------------------\n",
      "AttributeError: module '__main__' has no attribute '/Users/gautamprakash/Library/Jupyter/runtime/kernel-4ca4eb32-0594-4ea0-9725-3de00e7fcb24'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "class TestDetectGesturesApp(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        # Create a tkinter window\n",
    "        self.window = tk.Tk()\n",
    "\n",
    "        # Call the detect_gestures_app function to set up the UI\n",
    "        detect_gestures_app()\n",
    "\n",
    "    def tearDown(self):\n",
    "        # Close the tkinter window\n",
    "        self.window.destroy()\n",
    "\n",
    "    def test_button_visibility(self):\n",
    "        # Check if the button is visible\n",
    "        button_state = self.window.children['button'].cget('state')\n",
    "        self.assertEqual(button_state, 'normal', \"Button should be visible\")\n",
    "\n",
    "    def test_button_command(self):\n",
    "        # Call the button's command and check if it's working\n",
    "        button = self.window.children['button']\n",
    "        self.assertEqual(button.invoke(), None, \"Button command should return None\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c0167",
   "metadata": {},
   "source": [
    "# Interface testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd33cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.0.6-py3-none-any.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m526.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ipytest\n",
      "  Downloading ipytest-0.13.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipywidgets) (5.1.1)\n",
      "Collecting jupyterlab-widgets~=3.0.7\n",
      "  Downloading jupyterlab_widgets-3.0.7-py3-none-any.whl (198 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.2/198.2 kB\u001b[0m \u001b[31m650.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ipython>=6.1.0 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipywidgets) (8.4.0)\n",
      "Collecting widgetsnbextension~=4.0.7\n",
      "  Downloading widgetsnbextension-4.0.7-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m101.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: ipykernel>=4.5.1 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipywidgets) (6.15.2)\n",
      "Collecting pytest>=5.4\n",
      "  Downloading pytest-7.3.0-py3-none-any.whl (320 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.5/320.5 kB\u001b[0m \u001b[31m172.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipytest) (21.3)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.3.5)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: appnope in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: nest-asyncio in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.5)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (23.2.0)\n",
      "Requirement already satisfied: debugpy>=1.0 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (65.5.0)\n",
      "Requirement already satisfied: pickleshare in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: backcall in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: stack-data in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Collecting pluggy<2.0,>=0.12\n",
      "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting tomli>=1.0.0\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Collecting exceptiongroup>=1.0.0rc8\n",
      "  Downloading exceptiongroup-1.1.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from packaging->ipytest) (3.0.9)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: entrypoints in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.11.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: asttokens in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: executing in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Installing collected packages: widgetsnbextension, tomli, pluggy, jupyterlab-widgets, iniconfig, exceptiongroup, pytest, ipytest, ipywidgets\n",
      "Successfully installed exceptiongroup-1.1.1 iniconfig-2.0.0 ipytest-0.13.1 ipywidgets-8.0.6 jupyterlab-widgets-3.0.7 pluggy-1.0.0 pytest-7.3.0 tomli-2.0.1 widgetsnbextension-4.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets ipytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21443da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: ipywidgets in /opt/anaconda3/lib/python3.8/site-packages (7.6.3)\n",
      "Collecting ipytest\n",
      "  Using cached ipytest-0.13.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/anaconda3/lib/python3.8/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/anaconda3/lib/python3.8/site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from ipywidgets) (7.22.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/anaconda3/lib/python3.8/site-packages (from ipywidgets) (5.3.4)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/anaconda3/lib/python3.8/site-packages (from ipywidgets) (5.0.5)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: pytest>=5.4 in /opt/anaconda3/lib/python3.8/site-packages (from ipytest) (6.2.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.8/site-packages (from ipytest) (21.3)\n",
      "Requirement already satisfied: jupyter-client in /opt/anaconda3/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
      "Requirement already satisfied: appnope in /opt/anaconda3/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/anaconda3/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.17)\n",
      "Requirement already satisfied: pickleshare in /opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (52.0.0.post20210125)\n",
      "Requirement already satisfied: backcall in /opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pygments in /opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (5.0.9)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.17.2)\n",
      "Requirement already satisfied: ipython-genutils in /opt/anaconda3/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core in /opt/anaconda3/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.7.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/anaconda3/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/anaconda3/lib/python3.8/site-packages (from pytest>=5.4->ipytest) (20.3.0)\n",
      "Requirement already satisfied: iniconfig in /opt/anaconda3/lib/python3.8/site-packages (from pytest>=5.4->ipytest) (1.1.1)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in /opt/anaconda3/lib/python3.8/site-packages (from pytest>=5.4->ipytest) (0.13.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /opt/anaconda3/lib/python3.8/site-packages (from pytest>=5.4->ipytest) (1.10.0)\n",
      "Requirement already satisfied: toml in /opt/anaconda3/lib/python3.8/site-packages (from pytest>=5.4->ipytest) (0.10.2)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/anaconda3/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from packaging->ipytest) (2.4.7)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.17.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.1.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.10.1)\n",
      "Requirement already satisfied: nbconvert in /opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.0.7)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.9.4)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.0.0)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/anaconda3/lib/python3.8/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.3)\n",
      "Requirement already satisfied: bleach in /opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.3.0)\n",
      "Requirement already satisfied: defusedxml in /opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: testpath in /opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: async-generator in /opt/anaconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /opt/anaconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mInstalling collected packages: ipytest\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed ipytest-0.13.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                                                           [100%]\u001b[0m\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m_______________________________________ test_button_command ________________________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_button_command\u001b[39;49;00m():\n",
      "        label = widgets.Label(value=\u001b[33m\"\u001b[39;49;00m\u001b[33mWelcome to Detect Gestures App!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        button = widgets.Button(description=\u001b[33m\"\u001b[39;49;00m\u001b[33mDetect\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        vbox = VBox([label, button])\n",
      "    \n",
      "        \u001b[90m# Mock the button click event\u001b[39;49;00m\n",
      "        \u001b[94mdef\u001b[39;49;00m \u001b[92mmock_click\u001b[39;49;00m(button):\n",
      "            \u001b[94mpass\u001b[39;49;00m\n",
      "    \n",
      "        button.on_click(mock_click)\n",
      ">       \u001b[94massert\u001b[39;49;00m button.on_click == mock_click, \u001b[33m\"\u001b[39;49;00m\u001b[33mButton command should be set\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: Button command should be set\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/ct/83j70b6n0xn__16hfxpffk4m0000gn/T/ipykernel_24260/2094581323.py\u001b[0m:129: AssertionError\n",
      "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m t_23c033fd03ab4cdab0b53109bb0545a6.py::\u001b[1mtest_button_command\u001b[0m - AssertionError: Button command should be set\n",
      "\u001b[31m\u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m1 passed\u001b[0m\u001b[31m in 0.20s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.TESTS_FAILED: 1>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install ipywidgets ipytest\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import VBox\n",
    "import ipytest\n",
    "ipytest.autoconfig()\n",
    "\n",
    "# Define a simple GUI application\n",
    "def detect_gestures_app():\n",
    "    \n",
    "    # Create main window\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Hand Gesture Detection\")\n",
    "    root.geometry(\"500x300\")\n",
    "\n",
    "    label = tk.Label(root, text=\"Hand gesture detection system not yet started\")\n",
    "    label.pack(pady=20)\n",
    "\n",
    "    # Create label for messages\n",
    "    label = tk.Label(root, text=\"Click the button to detect hand gesture | Click Q to stop detection\", wraplength=250)\n",
    "    label.pack(pady=20)\n",
    "\n",
    "    # Create button for hand gesture detection\n",
    "    button = tk.Button(root, text=\"Detect Hand Gesture\", command=detect_gestures)\n",
    "    button.pack(pady=10)\n",
    "    # Create a function to be called by the button's on_click\n",
    "    def detect_gestures(button):\n",
    "        # Replace this with your actual gesture detection logic\n",
    "        print(\"Performing gesture detection...\")\n",
    "        # Placeholder for actual implementation\n",
    "        #pass\n",
    "        #label.config(text=\"Hand gesture system activated\")\n",
    "        # initialize mediapipe\n",
    "        mpHands = mp.solutions.hands\n",
    "        hands = mpHands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "        mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "        # Load the gesture recognizer model\n",
    "        model = load_model('mp_hand_gesture')\n",
    "\n",
    "        # Load class names\n",
    "        f = open('gesture.names', 'r')\n",
    "        classNames = f.read().split('\\n')\n",
    "        f.close()\n",
    "        print(classNames)\n",
    "\n",
    "        # Create a VideoCapture object to capture frames from the camera\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        # Initialize the MediaPipe Hand model\n",
    "        mp_hands = mp.solutions.hands\n",
    "        hands = mp_hands.Hands()\n",
    "\n",
    "        # Initialize the drawing module\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "        while True:\n",
    "            # Read each frame from the webcam\n",
    "            _, frame = cap.read()\n",
    "\n",
    "            x, y, c = frame.shape\n",
    "\n",
    "            # Flip the frame horizontally\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Get hand landmark prediction\n",
    "            result = hands.process(framergb)\n",
    "\n",
    "            # print(result)\n",
    "    \n",
    "            className = ''\n",
    "\n",
    "            # post process the result\n",
    "            if result.multi_hand_landmarks:\n",
    "                landmarks = []\n",
    "                for handslms in result.multi_hand_landmarks:\n",
    "                    for lm in handslms.landmark:\n",
    "                        # print(id, lm)\n",
    "                        lmx = int(lm.x * x)\n",
    "                        lmy = int(lm.y * y)\n",
    "\n",
    "                        landmarks.append([lmx, lmy])\n",
    "\n",
    "                    # Drawing landmarks on frames\n",
    "                    mpDraw.draw_landmarks(frame, handslms, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "                    # Predict gesture\n",
    "                    prediction = model.predict([landmarks])\n",
    "                    # print(prediction)\n",
    "                    classID = np.argmax(prediction)\n",
    "                    className = classNames[classID]\n",
    "                    print(className)\n",
    "\n",
    "            # show the prediction on the frame\n",
    "            cv2.putText(frame, className, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Show the final output\n",
    "            cv2.imshow(\"Output\", frame) \n",
    "\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "        # release the webcam and destroy all active windows\n",
    "        cap.release()\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "        button.on_click(perform_detection)\n",
    "\n",
    "# Define a test for button visibility\n",
    "def test_button_visibility():\n",
    "    label = widgets.Label(value=\"Welcome to Detect Gestures App!\")\n",
    "    button = widgets.Button(description=\"Detect\")\n",
    "    vbox = VBox([label, button])\n",
    "    assert button.layout.display != 'none', \"Button should be visible\"\n",
    "\n",
    "# Define a test for button command\n",
    "def test_button_command():\n",
    "    label = widgets.Label(value=\"Welcome to Detect Gestures App!\")\n",
    "    button = widgets.Button(description=\"Detect\")\n",
    "    vbox = VBox([label, button])\n",
    "    \n",
    "    # Mock the button click event\n",
    "    def mock_click(button):\n",
    "        pass\n",
    "    \n",
    "    button.on_click(mock_click)\n",
    "    assert button.on_click == mock_click, \"Button command should be set\"\n",
    "\n",
    "ipytest.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3054ecd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                                                           [100%]\u001b[0m\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m_______________________________________ test_button_command ________________________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_button_command\u001b[39;49;00m():\n",
      "        label = widgets.Label(value=\u001b[33m\"\u001b[39;49;00m\u001b[33mWelcome to Detect Gestures App!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        button = widgets.Button(description=\u001b[33m\"\u001b[39;49;00m\u001b[33mDetect\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        vbox = VBox([label, button])\n",
      "    \n",
      "        \u001b[90m# Mock the button click event\u001b[39;49;00m\n",
      "        \u001b[94mdef\u001b[39;49;00m \u001b[92mmock_click\u001b[39;49;00m(button):\n",
      "            \u001b[94mpass\u001b[39;49;00m\n",
      "    \n",
      "        button.on_click(mock_click)\n",
      ">       \u001b[94massert\u001b[39;49;00m button.on_click == mock_click, \u001b[33m\"\u001b[39;49;00m\u001b[33mButton command should be set\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: Button command should be set\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert <bound method Button.on_click of Button(description='Detect', style=ButtonStyle())> == <function test_button_command.<locals>.mock_click at 0x7fd01092c9d0>\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where <bound method Button.on_click of Button(description='Detect', style=ButtonStyle())> = Button(description='Detect', style=ButtonStyle()).on_click\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/ct/83j70b6n0xn__16hfxpffk4m0000gn/T/ipykernel_24260/3706714405.py\u001b[0m:53: AssertionError\n",
      "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m t_23c033fd03ab4cdab0b53109bb0545a6.py::\u001b[1mtest_button_command\u001b[0m - AssertionError: Button command should be set\n",
      "\u001b[31m\u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m1 passed\u001b[0m\u001b[31m in 0.03s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.TESTS_FAILED: 1>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import VBox\n",
    "import ipytest\n",
    "ipytest.autoconfig()\n",
    "\n",
    "# Define a simple GUI application\n",
    "def detect_gestures_app():\n",
    "    # Create main window\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Hand Gesture Detection\")\n",
    "    root.geometry(\"500x300\")\n",
    "\n",
    "    label = tk.Label(root, text=\"Hand gesture detection system not yet started\")\n",
    "    label.pack(pady=20)\n",
    "\n",
    "    # Create label for messages\n",
    "    label = tk.Label(root, text=\"Click the button to detect hand gesture | Click Q to stop detection\", wraplength=250)\n",
    "    label.pack(pady=20)\n",
    "\n",
    "    # Create button for hand gesture detection\n",
    "    button = tk.Button(root, text=\"Detect Hand Gesture\", command=perform_detection)  # Update this line\n",
    "    button.pack(pady=10)\n",
    "\n",
    "    # Function to perform gesture detection\n",
    "    def perform_detection():\n",
    "        # Replace this with your actual gesture detection logic\n",
    "        print(\"Performing gesture detection...\")\n",
    "        # Placeholder for actual implementation\n",
    "        # label.config(text=\"Hand gesture system activated\")\n",
    "        # initialize mediapipe\n",
    "        # ... (rest of the code)\n",
    "    \n",
    "    root.mainloop()\n",
    "\n",
    "# Define a test for button visibility\n",
    "def test_button_visibility():\n",
    "    label = widgets.Label(value=\"Welcome to Detect Gestures App!\")\n",
    "    button = widgets.Button(description=\"Detect\")\n",
    "    vbox = VBox([label, button])\n",
    "    assert button.layout.display != 'none', \"Button should be visible\"\n",
    "\n",
    "# Define a test for button command\n",
    "def test_button_command():\n",
    "    label = widgets.Label(value=\"Welcome to Detect Gestures App!\")\n",
    "    button = widgets.Button(description=\"Detect\")\n",
    "    vbox = VBox([label, button])\n",
    "    \n",
    "    # Mock the button click event\n",
    "    def mock_click(button):\n",
    "        pass\n",
    "    \n",
    "    button.on_click(mock_click)\n",
    "    assert button.on_click == mock_click, \"Button command should be set\"\n",
    "\n",
    "ipytest.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a2990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import VBox\n",
    "import ipytest\n",
    "ipytest.autoconfig()\n",
    "\n",
    "# Define a simple GUI application\n",
    "def detect_gestures_app():\n",
    "    # Your code for the GUI application here\n",
    "\n",
    "# Define a test for button visibility\n",
    "def test_button_visibility():\n",
    "    label = widgets.Label(value=\"Welcome to Detect Gestures App!\")\n",
    "    button = widgets.Button(description=\"Detect\")\n",
    "    vbox = VBox([label, button])\n",
    "    assert button.layout.display != 'none', \"Button should be visible\"\n",
    "\n",
    "# Define a test for button command\n",
    "def test_button_command():\n",
    "    label = widgets.Label(value=\"Welcome to Detect Gestures App!\")\n",
    "    button = widgets.Button(description=\"Detect\")\n",
    "    vbox = VBox([label, button])\n",
    "\n",
    "    # Mock the button click event\n",
    "    def mock_click(button):\n",
    "        pass\n",
    "    \n",
    "    button.on_click(mock_click)\n",
    "    assert button.on_click.callbacks[0].method == mock_click, \"Button command should be set\"\n",
    "\n",
    "ipytest.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d069b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                                                           [100%]\u001b[0m\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m_______________________________________ test_button_command ________________________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_button_command\u001b[39;49;00m():\n",
      "        label = widgets.Label(value=\u001b[33m\"\u001b[39;49;00m\u001b[33mWelcome to Detect Gestures App!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        button = widgets.Button(description=\u001b[33m\"\u001b[39;49;00m\u001b[33mDetect\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        vbox = VBox([label, button])\n",
      "    \n",
      "        \u001b[90m# Mock the button click event\u001b[39;49;00m\n",
      "        \u001b[94mdef\u001b[39;49;00m \u001b[92mmock_click\u001b[39;49;00m(button):\n",
      "            \u001b[94mpass\u001b[39;49;00m\n",
      "    \n",
      "        button.on_click(mock_click)\n",
      ">       \u001b[94massert\u001b[39;49;00m HasTraits.has_observers(button, \u001b[33m'\u001b[39;49;00m\u001b[33mon_click\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), \u001b[33m\"\u001b[39;49;00m\u001b[33mButton command should be set\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AttributeError: type object 'HasTraits' has no attribute 'has_observers'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/ct/83j70b6n0xn__16hfxpffk4m0000gn/T/ipykernel_24260/2022065813.py\u001b[0m:128: AttributeError\n",
      "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m t_23c033fd03ab4cdab0b53109bb0545a6.py::\u001b[1mtest_button_command\u001b[0m - AttributeError: type object 'HasTraits' has no attribute 'has_observers'\n",
      "\u001b[31m\u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m1 passed\u001b[0m\u001b[31m in 0.05s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.TESTS_FAILED: 1>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import VBox\n",
    "from traitlets import HasTraits\n",
    "import ipytest\n",
    "ipytest.autoconfig()\n",
    "\n",
    "# Define a simple GUI application\n",
    "def detect_gestures_app():\n",
    "    \n",
    "    # Create main window\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Hand Gesture Detection\")\n",
    "    root.geometry(\"500x300\")\n",
    "\n",
    "    label = tk.Label(root, text=\"Hand gesture detection system not yet started\")\n",
    "    label.pack(pady=20)\n",
    "\n",
    "    # Create label for messages\n",
    "    label = tk.Label(root, text=\"Click the button to detect hand gesture | Click Q to stop detection\", wraplength=250)\n",
    "    label.pack(pady=20)\n",
    "\n",
    "    # Create button for hand gesture detection\n",
    "    button = tk.Button(root, text=\"Detect Hand Gesture\", command=detect_gestures)\n",
    "    button.pack(pady=10)\n",
    "    # Create a function to be called by the button's on_click\n",
    "    def detect_gestures(button):\n",
    "        # Replace this with your actual gesture detection logic\n",
    "        print(\"Performing gesture detection...\")\n",
    "        # Placeholder for actual implementation\n",
    "        #pass\n",
    "        #label.config(text=\"Hand gesture system activated\")\n",
    "        # initialize mediapipe\n",
    "        mpHands = mp.solutions.hands\n",
    "        hands = mpHands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "        mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "        # Load the gesture recognizer model\n",
    "        model = load_model('mp_hand_gesture')\n",
    "\n",
    "        # Load class names\n",
    "        f = open('gesture.names', 'r')\n",
    "        classNames = f.read().split('\\n')\n",
    "        f.close()\n",
    "        print(classNames)\n",
    "\n",
    "        # Create a VideoCapture object to capture frames from the camera\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        # Initialize the MediaPipe Hand model\n",
    "        mp_hands = mp.solutions.hands\n",
    "        hands = mp_hands.Hands()\n",
    "\n",
    "        # Initialize the drawing module\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "        while True:\n",
    "            # Read each frame from the webcam\n",
    "            _, frame = cap.read()\n",
    "\n",
    "            x, y, c = frame.shape\n",
    "\n",
    "            # Flip the frame horizontally\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Get hand landmark prediction\n",
    "            result = hands.process(framergb)\n",
    "\n",
    "            # print(result)\n",
    "    \n",
    "            className = ''\n",
    "\n",
    "            # post process the result\n",
    "            if result.multi_hand_landmarks:\n",
    "                landmarks = []\n",
    "                for handslms in result.multi_hand_landmarks:\n",
    "                    for lm in handslms.landmark:\n",
    "                        # print(id, lm)\n",
    "                        lmx = int(lm.x * x)\n",
    "                        lmy = int(lm.y * y)\n",
    "\n",
    "                        landmarks.append([lmx, lmy])\n",
    "\n",
    "                    # Drawing landmarks on frames\n",
    "                    mpDraw.draw_landmarks(frame, handslms, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "                    # Predict gesture\n",
    "                    prediction = model.predict([landmarks])\n",
    "                    # print(prediction)\n",
    "                    classID = np.argmax(prediction)\n",
    "                    className = classNames[classID]\n",
    "                    print(className)\n",
    "\n",
    "            # show the prediction on the frame\n",
    "            cv2.putText(frame, className, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Show the final output\n",
    "            cv2.imshow(\"Output\", frame) \n",
    "\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "        # release the webcam and destroy all active windows\n",
    "        cap.release()\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "        button.on_click(perform_detection)\n",
    "\n",
    "# Define a test for button visibility\n",
    "def test_button_visibility():\n",
    "    label = widgets.Label(value=\"Welcome to Detect Gestures App!\")\n",
    "    button = widgets.Button(description=\"Detect\")\n",
    "    vbox = VBox([label, button])\n",
    "    assert button.layout.display != 'none', \"Button should be visible\"\n",
    "\n",
    "# Define a test for button command\n",
    "def test_button_command():\n",
    "    label = widgets.Label(value=\"Welcome to Detect Gestures App!\")\n",
    "    button = widgets.Button(description=\"Detect\")\n",
    "    vbox = VBox([label, button])\n",
    "\n",
    "    # Mock the button click event\n",
    "    def mock_click(button):\n",
    "        pass\n",
    "    \n",
    "    button.on_click(mock_click)\n",
    "    assert HasTraits.has_observers(button, 'on_click'), \"Button command should be set\"\n",
    "\n",
    "ipytest.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "302d70a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                                                                        [100%]\u001b[0m\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m_______________________________________ test_button_command ________________________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_button_command\u001b[39;49;00m():\n",
      "        label = widgets.Label(value=\u001b[33m\"\u001b[39;49;00m\u001b[33mWelcome to Detect Gestures App!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        button = widgets.Button(description=\u001b[33m\"\u001b[39;49;00m\u001b[33mDetect\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        vbox = VBox([label, button])\n",
      "    \n",
      "        \u001b[90m# Mock the button click event\u001b[39;49;00m\n",
      "        \u001b[94mdef\u001b[39;49;00m \u001b[92mmock_click\u001b[39;49;00m(button):\n",
      "            \u001b[94mpass\u001b[39;49;00m\n",
      "    \n",
      "        button.on_click(mock_click)\n",
      ">       \u001b[94massert\u001b[39;49;00m HasTraits.has_observers(button, \u001b[33m'\u001b[39;49;00m\u001b[33mon_click\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), \u001b[33m\"\u001b[39;49;00m\u001b[33mButton command should be set\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AttributeError: type object 'HasTraits' has no attribute 'has_observers'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/ct/83j70b6n0xn__16hfxpffk4m0000gn/T/ipykernel_24260/2995979540.py\u001b[0m:128: AttributeError\n",
      "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m t_23c033fd03ab4cdab0b53109bb0545a6.py::\u001b[1mtest_button_command\u001b[0m - AttributeError: type object 'HasTraits' has no attribute 'has_observers'\n",
      "\u001b[31m\u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m4 passed\u001b[0m\u001b[31m in 0.07s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.TESTS_FAILED: 1>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import VBox\n",
    "from traitlets import HasTraits\n",
    "import ipytest\n",
    "ipytest.autoconfig()\n",
    "\n",
    "# Define a simple GUI application\n",
    "def detect_gestures_app():\n",
    "    \n",
    "    # Create main window\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Hand Gesture Detection\")\n",
    "    root.geometry(\"500x300\")\n",
    "\n",
    "    label = tk.Label(root, text=\"Hand gesture detection system not yet started\")\n",
    "    label.pack(pady=20)\n",
    "\n",
    "    # Create label for messages\n",
    "    label = tk.Label(root, text=\"Click the button to detect hand gesture | Click Q to stop detection\", wraplength=250)\n",
    "    label.pack(pady=20)\n",
    "\n",
    "    # Create button for hand gesture detection\n",
    "    button = tk.Button(root, text=\"Detect Hand Gesture\", command=detect_gestures)\n",
    "    button.pack(pady=10)\n",
    "    # Create a function to be called by the button's on_click\n",
    "    def detect_gestures(button):\n",
    "        # Replace this with your actual gesture detection logic\n",
    "        print(\"Performing gesture detection...\")\n",
    "        # Placeholder for actual implementation\n",
    "        #pass\n",
    "        #label.config(text=\"Hand gesture system activated\")\n",
    "        # initialize mediapipe\n",
    "        mpHands = mp.solutions.hands\n",
    "        hands = mpHands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "        mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "        # Load the gesture recognizer model\n",
    "        model = load_model('mp_hand_gesture')\n",
    "\n",
    "        # Load class names\n",
    "        f = open('gesture.names', 'r')\n",
    "        classNames = f.read().split('\\n')\n",
    "        f.close()\n",
    "        print(classNames)\n",
    "\n",
    "        # Create a VideoCapture object to capture frames from the camera\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        # Initialize the MediaPipe Hand model\n",
    "        mp_hands = mp.solutions.hands\n",
    "        hands = mp_hands.Hands()\n",
    "\n",
    "        # Initialize the drawing module\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "        while True:\n",
    "            # Read each frame from the webcam\n",
    "            _, frame = cap.read()\n",
    "\n",
    "            x, y, c = frame.shape\n",
    "\n",
    "            # Flip the frame horizontally\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Get hand landmark prediction\n",
    "            result = hands.process(framergb)\n",
    "\n",
    "            # print(result)\n",
    "    \n",
    "            className = ''\n",
    "\n",
    "            # post process the result\n",
    "            if result.multi_hand_landmarks:\n",
    "                landmarks = []\n",
    "                for handslms in result.multi_hand_landmarks:\n",
    "                    for lm in handslms.landmark:\n",
    "                        # print(id, lm)\n",
    "                        lmx = int(lm.x * x)\n",
    "                        lmy = int(lm.y * y)\n",
    "\n",
    "                        landmarks.append([lmx, lmy])\n",
    "\n",
    "                    # Drawing landmarks on frames\n",
    "                    mpDraw.draw_landmarks(frame, handslms, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "                    # Predict gesture\n",
    "                    prediction = model.predict([landmarks])\n",
    "                    # print(prediction)\n",
    "                    classID = np.argmax(prediction)\n",
    "                    className = classNames[classID]\n",
    "                    print(className)\n",
    "\n",
    "            # show the prediction on the frame\n",
    "            cv2.putText(frame, className, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Show the final output\n",
    "            cv2.imshow(\"Output\", frame) \n",
    "\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "        # release the webcam and destroy all active windows\n",
    "        cap.release()\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "        button.on_click(perform_detection)\n",
    "\n",
    "# Define a test for button visibility\n",
    "def test_button_visibility():\n",
    "    label = widgets.Label(value=\"Welcome to Detect Gestures App!\")\n",
    "    button = widgets.Button(description=\"Detect\")\n",
    "    vbox = VBox([label, button])\n",
    "    assert button.layout.display != 'none', \"Button should be visible\"\n",
    "\n",
    "# Define a test for button command\n",
    "def test_button_command():\n",
    "    label = widgets.Label(value=\"Welcome to Detect Gestures App!\")\n",
    "    button = widgets.Button(description=\"Detect\")\n",
    "    vbox = VBox([label, button])\n",
    "\n",
    "    # Mock the button click event\n",
    "    def mock_click(button):\n",
    "        pass\n",
    "    \n",
    "    button.on_click(mock_click)\n",
    "    assert HasTraits.has_observers(button, 'on_click'), \"Button command should be set\"\n",
    "\n",
    "# Define a test for label value\n",
    "def test_label_value():\n",
    "    label_text = \"Welcome to Detect Gestures App!\"\n",
    "    label = widgets.Label(value=label_text)\n",
    "    button = widgets.Button(description=\"Detect\")\n",
    "    vbox = VBox([label, button])\n",
    "    assert label.value == label_text, \"Label value should match the provided text\"\n",
    "\n",
    "# Define a test for button description\n",
    "def test_button_description():\n",
    "    button_text = \"Detect\"\n",
    "    label = widgets.Label(value=\"Welcome to Detect Gestures App!\")\n",
    "    button = widgets.Button(description=button_text)\n",
    "    vbox = VBox([label, button])\n",
    "    assert button.description == button_text, \"Button description should match the provided text\"\n",
    "\n",
    "# Define a test for button click event handler\n",
    "def test_button_click_event():\n",
    "    label_text = \"Welcome to Detect Gestures App!\"\n",
    "    label = widgets.Label(value=label_text)\n",
    "    button_text = \"Detect\"\n",
    "    button = widgets.Button(description=button_text)\n",
    "    vbox = VBox([label, button])\n",
    "\n",
    "    # Mock the button click event\n",
    "    clicked = False\n",
    "    def mock_click(button):\n",
    "        nonlocal clicked\n",
    "        clicked = True\n",
    "    \n",
    "    button.on_click(mock_click)\n",
    "    button.click()\n",
    "    assert clicked, \"Button click event handler should be called\"\n",
    "\n",
    "ipytest.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b318cb",
   "metadata": {},
   "source": [
    "# User acceptance testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6e38e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytest in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (7.3.0)\n",
      "Requirement already satisfied: iniconfig in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from pytest) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from pytest) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from pytest) (1.1.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from pytest) (21.3)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from pytest) (2.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from packaging->pytest) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "089d82a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.8.3-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m34.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0mm\n",
      "\u001b[?25hCollecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.10.2-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from selenium) (2022.9.24)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from selenium) (1.26.12)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.9/384.9 kB\u001b[0m \u001b[31m34.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting async-generator>=1.9\n",
      "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting sortedcontainers\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m85.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sortedcontainers, sniffio, outcome, h11, async-generator, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed async-generator-1.10 h11-0.14.0 outcome-1.2.0 selenium-4.8.3 sniffio-1.3.0 sortedcontainers-2.4.0 trio-0.22.0 trio-websocket-0.10.2 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7adaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pytest\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Define a fixture to set up the Selenium WebDriver\n",
    "@pytest.fixture\n",
    "def driver():\n",
    "    # Use the appropriate WebDriver for your browser (e.g., Chrome, Firefox)\n",
    "    driver = webdriver.Safari()  # Replace with appropriate WebDriver\n",
    "    yield driver\n",
    "    driver.quit()\n",
    "\n",
    "# Define a test for the Detect Gestures App\n",
    "def test_detect_gestures_app(driver):\n",
    "    # Launch the Detect Gestures App in the browser\n",
    "    driver.get(\"http://localhost:8889/notebooks/Desktop/HCI%20project/GUI_program.ipynb\")  # Replace with the URL of your app\n",
    "    \n",
    "    # Wait for the app to load\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    wait.until(EC.presence_of_element_located((By.XPATH, \"//h1[text()='Detect Gestures App']\")))\n",
    "\n",
    "    # Find the input box and enter a sample input\n",
    "    input_box = driver.find_element(By.XPATH, \"//input[@id='input-box']\")\n",
    "    input_box.send_keys(\"sample input\")\n",
    "\n",
    "    # Find the Detect button and click it\n",
    "    detect_button = driver.find_element(By.XPATH, \"//button[@id='detect-button']\")\n",
    "    detect_button.click()\n",
    "\n",
    "    # Wait for the detection result\n",
    "    wait.until(EC.presence_of_element_located((By.XPATH, \"//div[@id='result']\")))\n",
    "\n",
    "    # Assert that the detection result is displayed correctly\n",
    "    result = driver.find_element(By.XPATH, \"//div[@id='result']\")\n",
    "    assert result.text == \"Detected gesture: sample gesture\", \"Detection result is incorrect\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bbe203f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyautogui\n",
      "  Downloading PyAutoGUI-0.9.53.tar.gz (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m320.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pymsgbox\n",
      "  Downloading PyMsgBox-1.0.9.tar.gz (18 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting PyTweening>=1.0.1\n",
      "  Downloading pytweening-1.0.4.tar.gz (14 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyscreeze>=0.1.21\n",
      "  Downloading PyScreeze-0.1.28.tar.gz (25 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pygetwindow>=0.0.5\n",
      "  Downloading PyGetWindow-0.0.9.tar.gz (9.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting mouseinfo\n",
      "  Downloading MouseInfo-0.1.3.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyobjc-core\n",
      "  Downloading pyobjc_core-9.0.1-cp39-cp39-macosx_10_9_universal2.whl (738 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.7/738.7 kB\u001b[0m \u001b[31m523.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyobjc\n",
      "  Downloading pyobjc-9.0.1-py3-none-any.whl (4.0 kB)\n",
      "Collecting pyrect\n",
      "  Downloading PyRect-0.2.0.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyperclip\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting rubicon-objc\n",
      "  Downloading rubicon_objc-0.4.5-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m651.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyobjc-framework-InputMethodKit==9.0.1\n",
      "  Downloading pyobjc_framework_InputMethodKit-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (7.4 kB)\n",
      "Collecting pyobjc-framework-MetalPerformanceShadersGraph==9.0.1\n",
      "  Downloading pyobjc_framework_MetalPerformanceShadersGraph-9.0.1-py2.py3-none-any.whl (5.4 kB)\n",
      "Collecting pyobjc-framework-SecurityInterface==9.0.1\n",
      "  Downloading pyobjc_framework_SecurityInterface-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (7.5 kB)\n",
      "Collecting pyobjc-framework-DiscRecording==9.0.1\n",
      "  Downloading pyobjc_framework_DiscRecording-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (12 kB)\n",
      "Collecting pyobjc-framework-ServiceManagement==9.0.1\n",
      "  Downloading pyobjc_framework_ServiceManagement-9.0.1-py2.py3-none-any.whl (4.8 kB)\n",
      "Collecting pyobjc-framework-FSEvents==9.0.1\n",
      "  Downloading pyobjc_framework_FSEvents-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (8.9 kB)\n",
      "Collecting pyobjc-framework-DictionaryServices==9.0.1\n",
      "  Downloading pyobjc_framework_DictionaryServices-9.0.1-py2.py3-none-any.whl (3.4 kB)\n",
      "Collecting pyobjc-framework-AVRouting==9.0.1\n",
      "  Downloading pyobjc_framework_AVRouting-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (6.0 kB)\n",
      "Collecting pyobjc-framework-CoreAudioKit==9.0.1\n",
      "  Downloading pyobjc_framework_CoreAudioKit-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (5.4 kB)\n",
      "Collecting pyobjc-framework-Accessibility==9.0.1\n",
      "  Downloading pyobjc_framework_Accessibility-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (7.1 kB)\n",
      "Collecting pyobjc-framework-Social==9.0.1\n",
      "  Downloading pyobjc_framework_Social-9.0.1-py2.py3-none-any.whl (4.0 kB)\n",
      "Collecting pyobjc-framework-DiscRecordingUI==9.0.1\n",
      "  Downloading pyobjc_framework_DiscRecordingUI-9.0.1-py2.py3-none-any.whl (4.3 kB)\n",
      "Collecting pyobjc-framework-CoreMediaIO==9.0.1\n",
      "  Downloading pyobjc_framework_CoreMediaIO-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (13 kB)\n",
      "Collecting pyobjc-framework-MediaToolbox==9.0.1\n",
      "  Downloading pyobjc_framework_MediaToolbox-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (8.3 kB)\n",
      "Collecting pyobjc-framework-Virtualization==9.0.1\n",
      "  Downloading pyobjc_framework_Virtualization-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (7.3 kB)\n",
      "Collecting pyobjc-framework-BackgroundAssets==9.0.1\n",
      "  Downloading pyobjc_framework_BackgroundAssets-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (6.8 kB)\n",
      "Collecting pyobjc-framework-CryptoTokenKit==9.0.1\n",
      "  Downloading pyobjc_framework_CryptoTokenKit-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (9.3 kB)\n",
      "Collecting pyobjc-framework-Vision==9.0.1\n",
      "  Downloading pyobjc_framework_Vision-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (13 kB)\n",
      "Collecting pyobjc-framework-LatentSemanticMapping==9.0.1\n",
      "  Downloading pyobjc_framework_LatentSemanticMapping-9.0.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting pyobjc-framework-ColorSync==9.0.1\n",
      "  Downloading pyobjc_framework_ColorSync-9.0.1-py2.py3-none-any.whl (5.5 kB)\n",
      "Collecting pyobjc-framework-UserNotificationsUI==9.0.1\n",
      "  Downloading pyobjc_framework_UserNotificationsUI-9.0.1-py2.py3-none-any.whl (3.5 kB)\n",
      "Collecting pyobjc-framework-NetworkExtension==9.0.1\n",
      "  Downloading pyobjc_framework_NetworkExtension-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (11 kB)\n",
      "Collecting pyobjc-framework-ScreenCaptureKit==9.0.1\n",
      "  Downloading pyobjc_framework_ScreenCaptureKit-9.0.1-cp39-cp39-macosx_10_9_universal2.whl (9.9 kB)\n",
      "Collecting pyobjc-framework-MediaLibrary==9.0.1\n",
      "  Downloading pyobjc_framework_MediaLibrary-9.0.1-py2.py3-none-any.whl (3.8 kB)\n",
      "Collecting pyobjc-framework-SharedWithYouCore==9.0.1\n",
      "  Downloading pyobjc_framework_SharedWithYouCore-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (6.0 kB)\n",
      "Collecting pyobjc-framework-NaturalLanguage==9.0.1\n",
      "  Downloading pyobjc_framework_NaturalLanguage-9.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting pyobjc-framework-SafetyKit==9.0.1\n",
      "  Downloading pyobjc_framework_SafetyKit-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (5.9 kB)\n",
      "Collecting pyobjc-framework-LocalAuthentication==9.0.1\n",
      "  Downloading pyobjc_framework_LocalAuthentication-9.0.1-py2.py3-none-any.whl (5.4 kB)\n",
      "Collecting pyobjc-framework-SearchKit==9.0.1\n",
      "  Downloading pyobjc_framework_SearchKit-9.0.1-py2.py3-none-any.whl (3.3 kB)\n",
      "Collecting pyobjc-framework-DVDPlayback==9.0.1\n",
      "  Downloading pyobjc_framework_DVDPlayback-9.0.1-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting pyobjc-framework-SceneKit==9.0.1\n",
      "  Downloading pyobjc_framework_SceneKit-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (22 kB)\n",
      "Collecting pyobjc-framework-SafariServices==9.0.1\n",
      "  Downloading pyobjc_framework_SafariServices-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (5.8 kB)\n",
      "Collecting pyobjc-framework-Automator==9.0.1\n",
      "  Downloading pyobjc_framework_Automator-9.0.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting pyobjc-framework-LocalAuthenticationEmbeddedUI==9.0.1\n",
      "  Downloading pyobjc_framework_LocalAuthenticationEmbeddedUI-9.0.1-py2.py3-none-any.whl (3.1 kB)\n",
      "Collecting pyobjc-framework-ExceptionHandling==9.0.1\n",
      "  Downloading pyobjc_framework_ExceptionHandling-9.0.1-py2.py3-none-any.whl (6.6 kB)\n",
      "Collecting pyobjc-framework-AppTrackingTransparency==9.0.1\n",
      "  Downloading pyobjc_framework_AppTrackingTransparency-9.0.1-py2.py3-none-any.whl (3.3 kB)\n",
      "Collecting pyobjc-framework-CoreAudio==9.0.1\n",
      "  Downloading pyobjc_framework_CoreAudio-9.0.1-cp39-cp39-macosx_10_9_universal2.whl (35 kB)\n",
      "Collecting pyobjc-framework-DataDetection==9.0.1\n",
      "  Downloading pyobjc_framework_DataDetection-9.0.1-py2.py3-none-any.whl (3.0 kB)\n",
      "Collecting pyobjc-framework-MultipeerConnectivity==9.0.1\n",
      "  Downloading pyobjc_framework_MultipeerConnectivity-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (8.8 kB)\n",
      "Collecting pyobjc-framework-PreferencePanes==9.0.1\n",
      "  Downloading pyobjc_framework_PreferencePanes-9.0.1-py2.py3-none-any.whl (4.3 kB)\n",
      "Collecting pyobjc-framework-MetalKit==9.0.1\n",
      "  Downloading pyobjc_framework_MetalKit-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (6.5 kB)\n",
      "Collecting pyobjc-framework-CoreMotion==9.0.1\n",
      "  Downloading pyobjc_framework_CoreMotion-9.0.1-cp39-cp39-macosx_10_9_universal2.whl (9.8 kB)\n",
      "Collecting pyobjc-framework-SyncServices==9.0.1\n",
      "  Downloading pyobjc_framework_SyncServices-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (10 kB)\n",
      "Collecting pyobjc-framework-ImageCaptureCore==9.0.1\n",
      "  Downloading pyobjc_framework_ImageCaptureCore-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (12 kB)\n",
      "Collecting pyobjc-framework-Photos==9.0.1\n",
      "  Downloading pyobjc_framework_Photos-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (9.4 kB)\n",
      "Collecting pyobjc-framework-Security==9.0.1\n",
      "  Downloading pyobjc_framework_Security-9.0.1-cp39-cp39-macosx_10_9_universal2.whl (40 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m83.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyobjc-framework-StoreKit==9.0.1\n",
      "  Downloading pyobjc_framework_StoreKit-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (8.6 kB)\n",
      "Collecting pyobjc-framework-AppleScriptKit==9.0.1\n",
      "  Downloading pyobjc_framework_AppleScriptKit-9.0.1-py2.py3-none-any.whl (3.9 kB)\n",
      "Collecting pyobjc-framework-PhotosUI==9.0.1\n",
      "  Downloading pyobjc_framework_PhotosUI-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (8.2 kB)\n",
      "Collecting pyobjc-framework-Contacts==9.0.1\n",
      "  Downloading pyobjc_framework_Contacts-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (9.1 kB)\n",
      "Collecting pyobjc-framework-CoreWLAN==9.0.1\n",
      "  Downloading pyobjc_framework_CoreWLAN-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (8.1 kB)\n",
      "Collecting pyobjc-framework-MetricKit==9.0.1\n",
      "  Downloading pyobjc_framework_MetricKit-9.0.1-cp39-cp39-macosx_10_9_universal2.whl (8.6 kB)\n",
      "Collecting pyobjc-framework-ExecutionPolicy==9.0.1\n",
      "  Downloading pyobjc_framework_ExecutionPolicy-9.0.1-py2.py3-none-any.whl (3.3 kB)\n",
      "Collecting pyobjc-framework-Network==9.0.1\n",
      "  Downloading pyobjc_framework_Network-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (14 kB)\n",
      "Collecting pyobjc-framework-SystemExtensions==9.0.1\n",
      "  Downloading pyobjc_framework_SystemExtensions-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (6.4 kB)\n",
      "Collecting pyobjc-framework-IOSurface==9.0.1\n",
      "  Downloading pyobjc_framework_IOSurface-9.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting pyobjc-framework-FinderSync==9.0.1\n",
      "  Downloading pyobjc_framework_FinderSync-9.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting pyobjc-framework-Metal==9.0.1\n",
      "  Downloading pyobjc_framework_Metal-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (37 kB)\n",
      "Collecting pyobjc-framework-CoreData==9.0.1\n",
      "  Downloading pyobjc_framework_CoreData-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (13 kB)\n",
      "Collecting pyobjc-framework-AppleScriptObjC==9.0.1\n",
      "  Downloading pyobjc_framework_AppleScriptObjC-9.0.1-py2.py3-none-any.whl (4.0 kB)\n",
      "Collecting pyobjc-framework-WebKit==9.0.1\n",
      "  Downloading pyobjc_framework_WebKit-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (29 kB)\n",
      "Collecting pyobjc-framework-VideoToolbox==9.0.1\n",
      "  Downloading pyobjc_framework_VideoToolbox-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (9.7 kB)\n",
      "Collecting pyobjc-framework-CloudKit==9.0.1\n",
      "  Downloading pyobjc_framework_CloudKit-9.0.1-py2.py3-none-any.whl (8.1 kB)\n",
      "Collecting pyobjc-framework-AdSupport==9.0.1\n",
      "  Downloading pyobjc_framework_AdSupport-9.0.1-py2.py3-none-any.whl (2.9 kB)\n",
      "Collecting pyobjc-framework-PushKit==9.0.1\n",
      "  Downloading pyobjc_framework_PushKit-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (5.9 kB)\n",
      "Collecting pyobjc-framework-SecurityFoundation==9.0.1\n",
      "  Downloading pyobjc_framework_SecurityFoundation-9.0.1-py2.py3-none-any.whl (3.3 kB)\n",
      "Collecting pyobjc-framework-SystemConfiguration==9.0.1\n",
      "  Downloading pyobjc_framework_SystemConfiguration-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (16 kB)\n",
      "Collecting pyobjc-framework-QuickLookThumbnailing==9.0.1\n",
      "  Downloading pyobjc_framework_QuickLookThumbnailing-9.0.1-py2.py3-none-any.whl (3.6 kB)\n",
      "Collecting pyobjc-framework-CalendarStore==9.0.1\n",
      "  Downloading pyobjc_framework_CalendarStore-9.0.1-py2.py3-none-any.whl (4.6 kB)\n",
      "Collecting pyobjc-framework-VideoSubscriberAccount==9.0.1\n",
      "  Downloading pyobjc_framework_VideoSubscriberAccount-9.0.1-py2.py3-none-any.whl (4.0 kB)\n",
      "Collecting pyobjc-framework-ClassKit==9.0.1\n",
      "  Downloading pyobjc_framework_ClassKit-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (6.3 kB)\n",
      "Collecting pyobjc-framework-ContactsUI==9.0.1\n",
      "  Downloading pyobjc_framework_ContactsUI-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (5.7 kB)\n",
      "Collecting pyobjc-framework-MapKit==9.0.1\n",
      "  Downloading pyobjc_framework_MapKit-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (15 kB)\n",
      "Collecting pyobjc-framework-AddressBook==9.0.1\n",
      "  Downloading pyobjc_framework_AddressBook-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (10 kB)\n",
      "Collecting pyobjc-framework-ModelIO==9.0.1\n",
      "  Downloading pyobjc_framework_ModelIO-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (15 kB)\n",
      "Collecting pyobjc-framework-ScreenTime==9.0.1\n",
      "  Downloading pyobjc_framework_ScreenTime-9.0.1-py2.py3-none-any.whl (3.1 kB)\n",
      "Collecting pyobjc-framework-ScriptingBridge==9.0.1\n",
      "  Downloading pyobjc_framework_ScriptingBridge-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (6.6 kB)\n",
      "Collecting pyobjc-framework-Collaboration==9.0.1\n",
      "  Downloading pyobjc_framework_Collaboration-9.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting pyobjc-framework-HealthKit==9.0.1\n",
      "  Downloading pyobjc_framework_HealthKit-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (14 kB)\n",
      "Collecting pyobjc-framework-CoreText==9.0.1\n",
      "  Downloading pyobjc_framework_CoreText-9.0.1-cp39-cp39-macosx_10_9_universal2.whl (30 kB)\n",
      "Collecting pyobjc-framework-DeviceCheck==9.0.1\n",
      "  Downloading pyobjc_framework_DeviceCheck-9.0.1-py2.py3-none-any.whl (3.2 kB)\n",
      "Collecting pyobjc-framework-ReplayKit==9.0.1\n",
      "  Downloading pyobjc_framework_ReplayKit-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (7.2 kB)\n",
      "Collecting pyobjc-framework-SoundAnalysis==9.0.1\n",
      "  Downloading pyobjc_framework_SoundAnalysis-9.0.1-py2.py3-none-any.whl (3.5 kB)\n",
      "Collecting pyobjc-framework-UniformTypeIdentifiers==9.0.1\n",
      "  Downloading pyobjc_framework_UniformTypeIdentifiers-9.0.1-py2.py3-none-any.whl (4.3 kB)\n",
      "Collecting pyobjc-framework-iTunesLibrary==9.0.1\n",
      "  Downloading pyobjc_framework_iTunesLibrary-9.0.1-py2.py3-none-any.whl (4.7 kB)\n",
      "Collecting pyobjc-framework-ThreadNetwork==9.0.1\n",
      "  Downloading pyobjc_framework_ThreadNetwork-9.0.1-py2.py3-none-any.whl (3.2 kB)\n",
      "Collecting pyobjc-framework-FileProvider==9.0.1\n",
      "  Downloading pyobjc_framework_FileProvider-9.0.1-cp39-cp39-macosx_10_9_universal2.whl (17 kB)\n",
      "Collecting pyobjc-framework-ExtensionKit==9.0.1\n",
      "  Downloading pyobjc_framework_ExtensionKit-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (5.8 kB)\n",
      "Collecting pyobjc-framework-NetFS==9.0.1\n",
      "  Downloading pyobjc_framework_NetFS-9.0.1-py2.py3-none-any.whl (3.8 kB)\n",
      "Collecting pyobjc-framework-EventKit==9.0.1\n",
      "  Downloading pyobjc_framework_EventKit-9.0.1-py2.py3-none-any.whl (5.9 kB)\n",
      "Collecting pyobjc-framework-InstantMessage==9.0.1\n",
      "  Downloading pyobjc_framework_InstantMessage-9.0.1-py2.py3-none-any.whl (4.9 kB)\n",
      "Collecting pyobjc-framework-Accounts==9.0.1\n",
      "  Downloading pyobjc_framework_Accounts-9.0.1-py2.py3-none-any.whl (4.6 kB)\n",
      "Collecting pyobjc-framework-GameKit==9.0.1\n",
      "  Downloading pyobjc_framework_GameKit-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (15 kB)\n",
      "Collecting pyobjc-framework-CoreMIDI==9.0.1\n",
      "  Downloading pyobjc_framework_CoreMIDI-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (12 kB)\n",
      "Collecting pyobjc-framework-LinkPresentation==9.0.1\n",
      "  Downloading pyobjc_framework_LinkPresentation-9.0.1-py2.py3-none-any.whl (3.3 kB)\n",
      "Collecting pyobjc-framework-Speech==9.0.1\n",
      "  Downloading pyobjc_framework_Speech-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (6.4 kB)\n",
      "Collecting pyobjc-framework-PencilKit==9.0.1\n",
      "  Downloading pyobjc_framework_PencilKit-9.0.1-py2.py3-none-any.whl (3.2 kB)\n",
      "Collecting pyobjc-framework-AudioVideoBridging==9.0.1\n",
      "  Downloading pyobjc_framework_AudioVideoBridging-9.0.1-py2.py3-none-any.whl (6.4 kB)\n",
      "Collecting pyobjc-framework-AutomaticAssessmentConfiguration==9.0.1\n",
      "  Downloading pyobjc_framework_AutomaticAssessmentConfiguration-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (6.4 kB)\n",
      "Collecting pyobjc-framework-CoreServices==9.0.1\n",
      "  Downloading pyobjc_framework_CoreServices-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (27 kB)\n",
      "Collecting pyobjc-framework-InstallerPlugins==9.0.1\n",
      "  Downloading pyobjc_framework_InstallerPlugins-9.0.1-py2.py3-none-any.whl (4.3 kB)\n",
      "Collecting pyobjc-framework-ApplicationServices==9.0.1\n",
      "  Downloading pyobjc_framework_ApplicationServices-9.0.1-cp39-cp39-macosx_10_9_universal2.whl (32 kB)\n",
      "Collecting pyobjc-framework-CoreLocation==9.0.1\n",
      "  Downloading pyobjc_framework_CoreLocation-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (9.4 kB)\n",
      "Collecting pyobjc-framework-PassKit==9.0.1\n",
      "  Downloading pyobjc_framework_PassKit-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (9.9 kB)\n",
      "Collecting pyobjc-framework-SpriteKit==9.0.1\n",
      "  Downloading pyobjc_framework_SpriteKit-9.0.1-cp39-cp39-macosx_10_9_universal2.whl (17 kB)\n",
      "Collecting pyobjc-framework-CoreMedia==9.0.1\n",
      "  Downloading pyobjc_framework_CoreMedia-9.0.1-cp39-cp39-macosx_10_9_universal2.whl (23 kB)\n",
      "Collecting pyobjc-framework-MLCompute==9.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading pyobjc_framework_MLCompute-9.0.1-py2.py3-none-any.whl (6.1 kB)\n",
      "Collecting pyobjc-framework-Cocoa==9.0.1\n",
      "  Downloading pyobjc_framework_Cocoa-9.0.1-cp39-cp39-macosx_10_9_universal2.whl (388 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.4/388.4 kB\u001b[0m \u001b[31m83.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyobjc-framework-CoreSpotlight==9.0.1\n",
      "  Downloading pyobjc_framework_CoreSpotlight-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (7.1 kB)\n",
      "Collecting pyobjc-framework-UserNotifications==9.0.1\n",
      "  Downloading pyobjc_framework_UserNotifications-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (7.3 kB)\n",
      "Collecting pyobjc-framework-ExternalAccessory==9.0.1\n",
      "  Downloading pyobjc_framework_ExternalAccessory-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (6.5 kB)\n",
      "Collecting pyobjc-framework-ShazamKit==9.0.1\n",
      "  Downloading pyobjc_framework_ShazamKit-9.0.1-cp39-cp39-macosx_10_9_universal2.whl (9.1 kB)\n",
      "Collecting pyobjc-framework-DiskArbitration==9.0.1\n",
      "  Downloading pyobjc_framework_DiskArbitration-9.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting pyobjc-framework-MetalPerformanceShaders==9.0.1\n",
      "  Downloading pyobjc_framework_MetalPerformanceShaders-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (20 kB)\n",
      "Collecting pyobjc-framework-OSAKit==9.0.1\n",
      "  Downloading pyobjc_framework_OSAKit-9.0.1-py2.py3-none-any.whl (3.6 kB)\n",
      "Collecting pyobjc-framework-Quartz==9.0.1\n",
      "  Downloading pyobjc_framework_Quartz-9.0.1-cp39-cp39-macosx_10_9_universal2.whl (227 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.9/227.9 kB\u001b[0m \u001b[31m235.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyobjc-framework-AVFoundation==9.0.1\n",
      "  Downloading pyobjc_framework_AVFoundation-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyobjc-framework-AVKit==9.0.1\n",
      "  Downloading pyobjc_framework_AVKit-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (8.1 kB)\n",
      "Collecting pyobjc-framework-CFNetwork==9.0.1\n",
      "  Downloading pyobjc_framework_CFNetwork-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (12 kB)\n",
      "Collecting pyobjc-framework-SharedWithYou==9.0.1\n",
      "  Downloading pyobjc_framework_SharedWithYou-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (6.4 kB)\n",
      "Collecting pyobjc-framework-CoreHaptics==9.0.1\n",
      "  Downloading pyobjc_framework_CoreHaptics-9.0.1-py2.py3-none-any.whl (4.7 kB)\n",
      "Collecting pyobjc-framework-CoreBluetooth==9.0.1\n",
      "  Downloading pyobjc_framework_CoreBluetooth-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (9.9 kB)\n",
      "Collecting pyobjc-framework-OSLog==9.0.1\n",
      "  Downloading pyobjc_framework_OSLog-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (5.8 kB)\n",
      "Collecting pyobjc-framework-libdispatch==9.0.1\n",
      "  Downloading pyobjc_framework_libdispatch-9.0.1-cp39-cp39-macosx_10_9_universal2.whl (20 kB)\n",
      "Collecting pyobjc-framework-MediaPlayer==9.0.1\n",
      "  Downloading pyobjc_framework_MediaPlayer-9.0.1-py2.py3-none-any.whl (6.1 kB)\n",
      "Collecting pyobjc-framework-GameController==9.0.1\n",
      "  Downloading pyobjc_framework_GameController-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (13 kB)\n",
      "Collecting pyobjc-framework-Intents==9.0.1\n",
      "  Downloading pyobjc_framework_Intents-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (21 kB)\n",
      "Collecting pyobjc-framework-GameCenter==9.0.1\n",
      "  Downloading pyobjc_framework_GameCenter-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (12 kB)\n",
      "Collecting pyobjc-framework-MailKit==9.0.1\n",
      "  Downloading pyobjc_framework_MailKit-9.0.1-py2.py3-none-any.whl (4.0 kB)\n",
      "Collecting pyobjc-framework-KernelManagement==9.0.1\n",
      "  Downloading pyobjc_framework_KernelManagement-9.0.1-py2.py3-none-any.whl (3.2 kB)\n",
      "Collecting pyobjc-framework-OpenDirectory==9.0.1\n",
      "  Downloading pyobjc_framework_OpenDirectory-9.0.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pyobjc-framework-CoreML==9.0.1\n",
      "  Downloading pyobjc_framework_CoreML-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (8.3 kB)\n",
      "Collecting pyobjc-framework-GameplayKit==9.0.1\n",
      "  Downloading pyobjc_framework_GameplayKit-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (9.3 kB)\n",
      "Collecting pyobjc-framework-MediaAccessibility==9.0.1\n",
      "  Downloading pyobjc_framework_MediaAccessibility-9.0.1-py2.py3-none-any.whl (3.9 kB)\n",
      "Collecting pyobjc-framework-NotificationCenter==9.0.1\n",
      "  Downloading pyobjc_framework_NotificationCenter-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (7.2 kB)\n",
      "Collecting pyobjc-framework-IntentsUI==9.0.1\n",
      "  Downloading pyobjc_framework_IntentsUI-9.0.1-cp39-cp39-macosx_10_9_universal2.whl (9.9 kB)\n",
      "Collecting pyobjc-framework-IMServicePlugIn==9.0.1\n",
      "  Downloading pyobjc_framework_IMServicePlugIn-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (9.5 kB)\n",
      "Collecting pyobjc-framework-AuthenticationServices==9.0.1\n",
      "  Downloading pyobjc_framework_AuthenticationServices-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (10 kB)\n",
      "Collecting pyobjc-framework-BusinessChat==9.0.1\n",
      "  Downloading pyobjc_framework_BusinessChat-9.0.1-py2.py3-none-any.whl (3.0 kB)\n",
      "Collecting pyobjc-framework-AdServices==9.0.1\n",
      "  Downloading pyobjc_framework_AdServices-9.0.1-py2.py3-none-any.whl (3.0 kB)\n",
      "Collecting pyobjc-framework-LaunchServices==9.0.1\n",
      "  Downloading pyobjc_framework_LaunchServices-9.0.1-py2.py3-none-any.whl (3.4 kB)\n",
      "Collecting pyobjc-framework-CallKit==9.0.1\n",
      "  Downloading pyobjc_framework_CallKit-9.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting pyobjc-framework-ScreenSaver==9.0.1\n",
      "  Downloading pyobjc_framework_ScreenSaver-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (6.3 kB)\n",
      "Collecting pyobjc-framework-MetalFX==9.0.1\n",
      "  Downloading pyobjc_framework_MetalFX-9.0.1-cp36-abi3-macosx_10_9_x86_64.whl (7.0 kB)\n",
      "Collecting pyobjc-framework-FileProviderUI==9.0.1\n",
      "  Downloading pyobjc_framework_FileProviderUI-9.0.1-py2.py3-none-any.whl (3.1 kB)\n",
      "Building wheels for collected packages: pyautogui, pygetwindow, pyscreeze, PyTweening, mouseinfo, pymsgbox, pyperclip, pyrect\n",
      "  Building wheel for pyautogui (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyautogui: filename=PyAutoGUI-0.9.53-py3-none-any.whl size=36599 sha256=cd82c0d482d327803bad9f3d12867960344cbcd610cc1d3d52a0b44096b78d23\n",
      "  Stored in directory: /Users/gautamprakash/Library/Caches/pip/wheels/d8/97/e4/d2edca92a87d3b5fbfb527264750a17b4ba297b9a7cab6e67f\n",
      "  Building wheel for pygetwindow (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pygetwindow: filename=PyGetWindow-0.0.9-py3-none-any.whl size=11064 sha256=347c3c0d65710aa0cff815cffe7de8b6671d5542ca0d2a411efc29e57c3275ec\n",
      "  Stored in directory: /Users/gautamprakash/Library/Caches/pip/wheels/44/ab/20/423c3a444793767e4e41f8377bc902f77bee212e68dcce85a5\n",
      "  Building wheel for pyscreeze (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyscreeze: filename=PyScreeze-0.1.28-py3-none-any.whl size=13010 sha256=43ca7b687077ed89bc415e92a511a9fd40117ae738fdf448f04ec2895b471dc4\n",
      "  Stored in directory: /Users/gautamprakash/Library/Caches/pip/wheels/a2/5b/86/99f1d8fac5d92de0ccb3f0d4ad15e3f4278baf75a9b0f20b93\n",
      "  Building wheel for PyTweening (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyTweening: filename=pytweening-1.0.4-py3-none-any.whl size=5836 sha256=1af33d1ebcca4608302a7d873141b9e3bc45ecd265719ebe02bfa1f31263cc9d\n",
      "  Stored in directory: /Users/gautamprakash/Library/Caches/pip/wheels/a4/5d/d2/ba4c8f82163233ffaadcf383c1e34d7d92635d357d13e7b78d\n",
      "  Building wheel for mouseinfo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mouseinfo: filename=MouseInfo-0.1.3-py3-none-any.whl size=10893 sha256=1c983033ae805a2b56b195d990560436c02c31d574f32bb203796e693b6fcd5b\n",
      "  Stored in directory: /Users/gautamprakash/Library/Caches/pip/wheels/61/73/b9/6fb1131ab36e650206e3aa0ad7a68907b41b32ac2d4f75f543\n",
      "  Building wheel for pymsgbox (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pymsgbox: filename=PyMsgBox-1.0.9-py3-none-any.whl size=7406 sha256=10abb991c448394714be6345f66e417480b49434080ee1070f095f8356358601\n",
      "  Stored in directory: /Users/gautamprakash/Library/Caches/pip/wheels/7f/13/8c/584c519464297d9637f9cd29fd1dcdf55e2a2cab225c76a2db\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11125 sha256=dcaa46de1e56320ea03530f42f6422508a04894abdb9c59001829b9fa7e599d7\n",
      "  Stored in directory: /Users/gautamprakash/Library/Caches/pip/wheels/0c/09/9e/49e21a6840ef7955b06d47394afef0058f0378c0914e48b8b8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for pyrect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyrect: filename=PyRect-0.2.0-py2.py3-none-any.whl size=11181 sha256=eafb26411a630dc2033523e79a67f8a729f8b6f40c961b5751ee0f2c575d5397\n",
      "  Stored in directory: /Users/gautamprakash/Library/Caches/pip/wheels/25/80/fa/27bb4a1c2e21f64ec71390489d52e57b7cc8afbe79bd595c5e\n",
      "Successfully built pyautogui pygetwindow pyscreeze PyTweening mouseinfo pymsgbox pyperclip pyrect\n",
      "Installing collected packages: PyTweening, pyscreeze, pyrect, pyperclip, pymsgbox, rubicon-objc, pyobjc-core, pygetwindow, pyobjc-framework-libdispatch, pyobjc-framework-Cocoa, mouseinfo, pyobjc-framework-WebKit, pyobjc-framework-Virtualization, pyobjc-framework-VideoSubscriberAccount, pyobjc-framework-UserNotifications, pyobjc-framework-UniformTypeIdentifiers, pyobjc-framework-ThreadNetwork, pyobjc-framework-SystemExtensions, pyobjc-framework-SystemConfiguration, pyobjc-framework-StoreKit, pyobjc-framework-Speech, pyobjc-framework-SoundAnalysis, pyobjc-framework-Social, pyobjc-framework-ShazamKit, pyobjc-framework-SharedWithYouCore, pyobjc-framework-ServiceManagement, pyobjc-framework-Security, pyobjc-framework-ScriptingBridge, pyobjc-framework-ScreenTime, pyobjc-framework-ScreenSaver, pyobjc-framework-SafariServices, pyobjc-framework-ReplayKit, pyobjc-framework-Quartz, pyobjc-framework-PushKit, pyobjc-framework-PreferencePanes, pyobjc-framework-PhotosUI, pyobjc-framework-Photos, pyobjc-framework-PencilKit, pyobjc-framework-PassKit, pyobjc-framework-OSAKit, pyobjc-framework-OpenDirectory, pyobjc-framework-NotificationCenter, pyobjc-framework-NetworkExtension, pyobjc-framework-Network, pyobjc-framework-NetFS, pyobjc-framework-NaturalLanguage, pyobjc-framework-MultipeerConnectivity, pyobjc-framework-MLCompute, pyobjc-framework-MetricKit, pyobjc-framework-Metal, pyobjc-framework-MediaToolbox, pyobjc-framework-MediaAccessibility, pyobjc-framework-MailKit, pyobjc-framework-LatentSemanticMapping, pyobjc-framework-KernelManagement, pyobjc-framework-iTunesLibrary, pyobjc-framework-IOSurface, pyobjc-framework-Intents, pyobjc-framework-InstallerPlugins, pyobjc-framework-InputMethodKit, pyobjc-framework-IMServicePlugIn, pyobjc-framework-ImageCaptureCore, pyobjc-framework-HealthKit, pyobjc-framework-GameController, pyobjc-framework-GameCenter, pyobjc-framework-FSEvents, pyobjc-framework-FinderSync, pyobjc-framework-FileProvider, pyobjc-framework-ExternalAccessory, pyobjc-framework-ExtensionKit, pyobjc-framework-ExecutionPolicy, pyobjc-framework-ExceptionHandling, pyobjc-framework-EventKit, pyobjc-framework-DVDPlayback, pyobjc-framework-DiskArbitration, pyobjc-framework-DiscRecording, pyobjc-framework-DeviceCheck, pyobjc-framework-DataDetection, pyobjc-framework-CryptoTokenKit, pyobjc-framework-CoreWLAN, pyobjc-framework-CoreSpotlight, pyobjc-framework-CoreMotion, pyobjc-framework-CoreML, pyobjc-framework-CoreMIDI, pyobjc-framework-CoreMediaIO, pyobjc-framework-CoreMedia, pyobjc-framework-CoreLocation, pyobjc-framework-CoreHaptics, pyobjc-framework-CoreData, pyobjc-framework-CoreBluetooth, pyobjc-framework-CoreAudio, pyobjc-framework-Contacts, pyobjc-framework-ColorSync, pyobjc-framework-Collaboration, pyobjc-framework-ClassKit, pyobjc-framework-CFNetwork, pyobjc-framework-CallKit, pyobjc-framework-CalendarStore, pyobjc-framework-BusinessChat, pyobjc-framework-BackgroundAssets, pyobjc-framework-AVRouting, pyobjc-framework-Automator, pyobjc-framework-AutomaticAssessmentConfiguration, pyobjc-framework-AuthenticationServices, pyobjc-framework-AudioVideoBridging, pyobjc-framework-AppTrackingTransparency, pyobjc-framework-AppleScriptObjC, pyobjc-framework-AppleScriptKit, pyobjc-framework-AdSupport, pyobjc-framework-AdServices, pyobjc-framework-AddressBook, pyobjc-framework-Accounts, pyobjc-framework-Vision, pyobjc-framework-VideoToolbox, pyobjc-framework-UserNotificationsUI, pyobjc-framework-SyncServices, pyobjc-framework-SpriteKit, pyobjc-framework-SharedWithYou, pyobjc-framework-SecurityInterface, pyobjc-framework-SecurityFoundation, pyobjc-framework-ScreenCaptureKit, pyobjc-framework-SceneKit, pyobjc-framework-SafetyKit, pyobjc-framework-QuickLookThumbnailing, pyobjc-framework-OSLog, pyobjc-framework-ModelIO, pyobjc-framework-MetalPerformanceShaders, pyobjc-framework-MetalKit, pyobjc-framework-MetalFX, pyobjc-framework-MediaLibrary, pyobjc-framework-MapKit, pyobjc-framework-LocalAuthentication, pyobjc-framework-LinkPresentation, pyobjc-framework-IntentsUI, pyobjc-framework-InstantMessage, pyobjc-framework-GameKit, pyobjc-framework-FileProviderUI, pyobjc-framework-DiscRecordingUI, pyobjc-framework-CoreText, pyobjc-framework-CoreServices, pyobjc-framework-CoreAudioKit, pyobjc-framework-ContactsUI, pyobjc-framework-CloudKit, pyobjc-framework-AVKit, pyobjc-framework-AVFoundation, pyobjc-framework-ApplicationServices, pyobjc-framework-Accessibility, pyobjc-framework-SearchKit, pyobjc-framework-MetalPerformanceShadersGraph, pyobjc-framework-MediaPlayer, pyobjc-framework-LocalAuthenticationEmbeddedUI, pyobjc-framework-LaunchServices, pyobjc-framework-GameplayKit, pyobjc-framework-DictionaryServices, pyobjc, pyautogui\n",
      "Successfully installed PyTweening-1.0.4 mouseinfo-0.1.3 pyautogui-0.9.53 pygetwindow-0.0.9 pymsgbox-1.0.9 pyobjc-9.0.1 pyobjc-core-9.0.1 pyobjc-framework-AVFoundation-9.0.1 pyobjc-framework-AVKit-9.0.1 pyobjc-framework-AVRouting-9.0.1 pyobjc-framework-Accessibility-9.0.1 pyobjc-framework-Accounts-9.0.1 pyobjc-framework-AdServices-9.0.1 pyobjc-framework-AdSupport-9.0.1 pyobjc-framework-AddressBook-9.0.1 pyobjc-framework-AppTrackingTransparency-9.0.1 pyobjc-framework-AppleScriptKit-9.0.1 pyobjc-framework-AppleScriptObjC-9.0.1 pyobjc-framework-ApplicationServices-9.0.1 pyobjc-framework-AudioVideoBridging-9.0.1 pyobjc-framework-AuthenticationServices-9.0.1 pyobjc-framework-AutomaticAssessmentConfiguration-9.0.1 pyobjc-framework-Automator-9.0.1 pyobjc-framework-BackgroundAssets-9.0.1 pyobjc-framework-BusinessChat-9.0.1 pyobjc-framework-CFNetwork-9.0.1 pyobjc-framework-CalendarStore-9.0.1 pyobjc-framework-CallKit-9.0.1 pyobjc-framework-ClassKit-9.0.1 pyobjc-framework-CloudKit-9.0.1 pyobjc-framework-Cocoa-9.0.1 pyobjc-framework-Collaboration-9.0.1 pyobjc-framework-ColorSync-9.0.1 pyobjc-framework-Contacts-9.0.1 pyobjc-framework-ContactsUI-9.0.1 pyobjc-framework-CoreAudio-9.0.1 pyobjc-framework-CoreAudioKit-9.0.1 pyobjc-framework-CoreBluetooth-9.0.1 pyobjc-framework-CoreData-9.0.1 pyobjc-framework-CoreHaptics-9.0.1 pyobjc-framework-CoreLocation-9.0.1 pyobjc-framework-CoreMIDI-9.0.1 pyobjc-framework-CoreML-9.0.1 pyobjc-framework-CoreMedia-9.0.1 pyobjc-framework-CoreMediaIO-9.0.1 pyobjc-framework-CoreMotion-9.0.1 pyobjc-framework-CoreServices-9.0.1 pyobjc-framework-CoreSpotlight-9.0.1 pyobjc-framework-CoreText-9.0.1 pyobjc-framework-CoreWLAN-9.0.1 pyobjc-framework-CryptoTokenKit-9.0.1 pyobjc-framework-DVDPlayback-9.0.1 pyobjc-framework-DataDetection-9.0.1 pyobjc-framework-DeviceCheck-9.0.1 pyobjc-framework-DictionaryServices-9.0.1 pyobjc-framework-DiscRecording-9.0.1 pyobjc-framework-DiscRecordingUI-9.0.1 pyobjc-framework-DiskArbitration-9.0.1 pyobjc-framework-EventKit-9.0.1 pyobjc-framework-ExceptionHandling-9.0.1 pyobjc-framework-ExecutionPolicy-9.0.1 pyobjc-framework-ExtensionKit-9.0.1 pyobjc-framework-ExternalAccessory-9.0.1 pyobjc-framework-FSEvents-9.0.1 pyobjc-framework-FileProvider-9.0.1 pyobjc-framework-FileProviderUI-9.0.1 pyobjc-framework-FinderSync-9.0.1 pyobjc-framework-GameCenter-9.0.1 pyobjc-framework-GameController-9.0.1 pyobjc-framework-GameKit-9.0.1 pyobjc-framework-GameplayKit-9.0.1 pyobjc-framework-HealthKit-9.0.1 pyobjc-framework-IMServicePlugIn-9.0.1 pyobjc-framework-IOSurface-9.0.1 pyobjc-framework-ImageCaptureCore-9.0.1 pyobjc-framework-InputMethodKit-9.0.1 pyobjc-framework-InstallerPlugins-9.0.1 pyobjc-framework-InstantMessage-9.0.1 pyobjc-framework-Intents-9.0.1 pyobjc-framework-IntentsUI-9.0.1 pyobjc-framework-KernelManagement-9.0.1 pyobjc-framework-LatentSemanticMapping-9.0.1 pyobjc-framework-LaunchServices-9.0.1 pyobjc-framework-LinkPresentation-9.0.1 pyobjc-framework-LocalAuthentication-9.0.1 pyobjc-framework-LocalAuthenticationEmbeddedUI-9.0.1 pyobjc-framework-MLCompute-9.0.1 pyobjc-framework-MailKit-9.0.1 pyobjc-framework-MapKit-9.0.1 pyobjc-framework-MediaAccessibility-9.0.1 pyobjc-framework-MediaLibrary-9.0.1 pyobjc-framework-MediaPlayer-9.0.1 pyobjc-framework-MediaToolbox-9.0.1 pyobjc-framework-Metal-9.0.1 pyobjc-framework-MetalFX-9.0.1 pyobjc-framework-MetalKit-9.0.1 pyobjc-framework-MetalPerformanceShaders-9.0.1 pyobjc-framework-MetalPerformanceShadersGraph-9.0.1 pyobjc-framework-MetricKit-9.0.1 pyobjc-framework-ModelIO-9.0.1 pyobjc-framework-MultipeerConnectivity-9.0.1 pyobjc-framework-NaturalLanguage-9.0.1 pyobjc-framework-NetFS-9.0.1 pyobjc-framework-Network-9.0.1 pyobjc-framework-NetworkExtension-9.0.1 pyobjc-framework-NotificationCenter-9.0.1 pyobjc-framework-OSAKit-9.0.1 pyobjc-framework-OSLog-9.0.1 pyobjc-framework-OpenDirectory-9.0.1 pyobjc-framework-PassKit-9.0.1 pyobjc-framework-PencilKit-9.0.1 pyobjc-framework-Photos-9.0.1 pyobjc-framework-PhotosUI-9.0.1 pyobjc-framework-PreferencePanes-9.0.1 pyobjc-framework-PushKit-9.0.1 pyobjc-framework-Quartz-9.0.1 pyobjc-framework-QuickLookThumbnailing-9.0.1 pyobjc-framework-ReplayKit-9.0.1 pyobjc-framework-SafariServices-9.0.1 pyobjc-framework-SafetyKit-9.0.1 pyobjc-framework-SceneKit-9.0.1 pyobjc-framework-ScreenCaptureKit-9.0.1 pyobjc-framework-ScreenSaver-9.0.1 pyobjc-framework-ScreenTime-9.0.1 pyobjc-framework-ScriptingBridge-9.0.1 pyobjc-framework-SearchKit-9.0.1 pyobjc-framework-Security-9.0.1 pyobjc-framework-SecurityFoundation-9.0.1 pyobjc-framework-SecurityInterface-9.0.1 pyobjc-framework-ServiceManagement-9.0.1 pyobjc-framework-SharedWithYou-9.0.1 pyobjc-framework-SharedWithYouCore-9.0.1 pyobjc-framework-ShazamKit-9.0.1 pyobjc-framework-Social-9.0.1 pyobjc-framework-SoundAnalysis-9.0.1 pyobjc-framework-Speech-9.0.1 pyobjc-framework-SpriteKit-9.0.1 pyobjc-framework-StoreKit-9.0.1 pyobjc-framework-SyncServices-9.0.1 pyobjc-framework-SystemConfiguration-9.0.1 pyobjc-framework-SystemExtensions-9.0.1 pyobjc-framework-ThreadNetwork-9.0.1 pyobjc-framework-UniformTypeIdentifiers-9.0.1 pyobjc-framework-UserNotifications-9.0.1 pyobjc-framework-UserNotificationsUI-9.0.1 pyobjc-framework-VideoSubscriberAccount-9.0.1 pyobjc-framework-VideoToolbox-9.0.1 pyobjc-framework-Virtualization-9.0.1 pyobjc-framework-Vision-9.0.1 pyobjc-framework-WebKit-9.0.1 pyobjc-framework-iTunesLibrary-9.0.1 pyobjc-framework-libdispatch-9.0.1 pyperclip-1.8.2 pyrect-0.2.0 pyscreeze-0.1.28 rubicon-objc-0.4.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a65ee632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytest in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (7.3.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from pytest) (2.0.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from pytest) (21.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from pytest) (1.1.1)\n",
      "Requirement already satisfied: iniconfig in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from pytest) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from pytest) (1.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from packaging->pytest) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ddd962b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement subprocess (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for subprocess\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cbae4b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'failcheck' from 'pyautogui' (/opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages/pyautogui/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytest\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyautogui\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m click, write, hotkey, locateOnScreen, press, failcheck\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Define a fixture to start the GUI application\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;129m@pytest\u001b[39m\u001b[38;5;241m.\u001b[39mfixture\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_app\u001b[39m():\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Start the GUI application using subprocess\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'failcheck' from 'pyautogui' (/opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages/pyautogui/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pytest\n",
    "import subprocess\n",
    "from pyautogui import click, write, hotkey, locateOnScreen, press, failcheck\n",
    "\n",
    "# Define a fixture to start the GUI application\n",
    "@pytest.fixture\n",
    "def start_app():\n",
    "    # Start the GUI application using subprocess\n",
    "    app_process = subprocess.Popen(['python', 'gui_app.py'])  # Replace with the command to start your GUI application\n",
    "    time.sleep(5)  # Wait for the GUI application to start\n",
    "    yield\n",
    "    # Clean up after the test\n",
    "    app_process.terminate()\n",
    "    app_process.wait()\n",
    "\n",
    "# Define a test for the GUI application\n",
    "def test_gui_app(start_app):\n",
    "    # Locate and click the input box\n",
    "    input_box_location = locateOnScreen('input_box.png')  # Replace with the path to the image of the input box in your application\n",
    "    assert input_box_location, \"Input box not found\"\n",
    "    click(input_box_location)\n",
    "\n",
    "    # Enter sample input in the input box\n",
    "    write('sample input')\n",
    "\n",
    "    # Locate and click the detect button\n",
    "    detect_button_location = locateOnScreen('detect_button.png')  # Replace with the path to the image of the detect button in your application\n",
    "    assert detect_button_location, \"Detect button not found\"\n",
    "    click(detect_button_location)\n",
    "\n",
    "    # Wait for the detection result to appear\n",
    "    time.sleep(5)  # Replace with an appropriate wait time based on your application's performance\n",
    "    result_location = locateOnScreen('result.png')  # Replace with the path to the image of the detection result in your application\n",
    "    assert result_location, \"Detection result not found\"\n",
    "\n",
    "    # Assert that the detection result is displayed correctly\n",
    "    result_text = get_text_from_image(result_location)  # Replace with a function to extract text from the image at the given location\n",
    "    assert result_text == \"Detected gesture: sample gesture\", \"Detection result is incorrect\"\n",
    "\n",
    "# Helper function to extract text from an image\n",
    "def get_text_from_image(image_location):\n",
    "    # Replace with appropriate code to extract text from the image\n",
    "    return \"Detected gesture: sample gesture\"  # Replace with the actual extracted text from the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6973b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pytest\n",
    "import subprocess\n",
    "from pyautogui import click, write, hotkey, locateOnScreen, press\n",
    "\n",
    "# Define a fixture to start the GUI application\n",
    "@pytest.fixture\n",
    "def start_app():\n",
    "    # Start the GUI application using subprocess\n",
    "    app_process = subprocess.Popen(['python', 'gui_app.py'])  # Replace with the command to start your GUI application\n",
    "    time.sleep(5)  # Wait for the GUI application to start\n",
    "    yield\n",
    "    # Clean up after the test\n",
    "    app_process.terminate()\n",
    "    app_process.wait()\n",
    "\n",
    "# Define a test for the GUI application\n",
    "def test_gui_app(start_app):\n",
    "    # Locate and click the input box\n",
    "    input_box_location = locateOnScreen('input_box.png')  # Replace with the path to the image of the input box in your application\n",
    "    assert input_box_location, \"Input box not found\"\n",
    "    click(input_box_location)\n",
    "\n",
    "    # Enter sample input in the input box\n",
    "    write('sample input')\n",
    "\n",
    "    # Locate and click the detect button\n",
    "    detect_button_location = locateOnScreen('detect_button.png')  # Replace with the path to the image of the detect button in your application\n",
    "    assert detect_button_location, \"Detect button not found\"\n",
    "    click(detect_button_location)\n",
    "\n",
    "    # Wait for the detection result to appear\n",
    "    time.sleep(5)  # Replace with an appropriate wait time based on your application's performance\n",
    "    result_location = locateOnScreen('result.png')  # Replace with the path to the image of the detection result in your application\n",
    "    assert result_location, \"Detection result not found\"\n",
    "\n",
    "    # Assert that the detection result is displayed correctly\n",
    "    result_text = get_text_from_image(result_location)  # Replace with a function to extract text from the image at the given location\n",
    "    assert result_text == \"Detected gesture: sample gesture\", \"Detection result is incorrect\"\n",
    "\n",
    "# Helper function to extract text from an image\n",
    "def get_text_from_image(image_location):\n",
    "    # Replace with appropriate code to extract text from the image\n",
    "    return \"Detected gesture: sample gesture\"  # Replace with the actual extracted text from the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e53d11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pytest\n",
    "import subprocess\n",
    "from pyautogui import click, write, hotkey, locateOnScreen, press, screenshot\n",
    "\n",
    "# Define a fixture to start the GUI application\n",
    "@pytest.fixture\n",
    "def start_app():\n",
    "    # Start the GUI application using subprocess\n",
    "    app_process = subprocess.Popen(['python', 'gui_app.py'])  # Replace with the command to start your GUI application\n",
    "    time.sleep(5)  # Wait for the GUI application to start\n",
    "    yield\n",
    "    # Clean up after the test\n",
    "    app_process.terminate()\n",
    "    app_process.wait()\n",
    "\n",
    "# Define a test for the GUI application\n",
    "def test_hand_gesture_app(start_app):\n",
    "    # Locate and click the input box\n",
    "    input_box_location = locateOnScreen('input_box.png')  # Replace with the path to the image of the input box in your application\n",
    "    assert input_box_location, \"Input box not found\"\n",
    "    click(input_box_location)\n",
    "\n",
    "    # Enter sample input in the input box\n",
    "    write('sample input')\n",
    "\n",
    "    # Locate and click the detect button\n",
    "    detect_button_location = locateOnScreen('detect_button.png')  # Replace with the path to the image of the detect button in your application\n",
    "    assert detect_button_location, \"Detect button not found\"\n",
    "    click(detect_button_location)\n",
    "\n",
    "    # Wait for the detection result to appear\n",
    "    time.sleep(5)  # Replace with an appropriate wait time based on your application's performance\n",
    "    result_location = locateOnScreen('result.png')  # Replace with the path to the image of the detection result in your application\n",
    "    assert result_location, \"Detection result not found\"\n",
    "\n",
    "    # Assert that the detection result is displayed correctly\n",
    "    result_text = get_text_from_image(result_location)\n",
    "    assert result_text == \"Detected gesture: sample gesture\", \"Detection result is incorrect\"\n",
    "\n",
    "# Helper function to extract text from an image\n",
    "def get_text_from_image(image_location):\n",
    "    screenshot_image = screenshot()  # Capture a screenshot\n",
    "    result_image = screenshot_image.crop((image_location.left, image_location.top, image_location.right, image_location.bottom))  # Crop the image at the given location\n",
    "    result_text = \"Detected gesture: sample gesture\"  # Replace with appropriate logic to extract text from the image\n",
    "    return result_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36aae456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: /Users/gautamprakash/Library/Jupyter/runtime/kernel-4ca4eb32-0594-4ea0-9725-3de00e7fcb24 (unittest.loader._FailedTest)\n",
      "----------------------------------------------------------------------\n",
      "AttributeError: module '__main__' has no attribute '/Users/gautamprakash/Library/Jupyter/runtime/kernel-4ca4eb32-0594-4ea0-9725-3de00e7fcb24'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import subprocess\n",
    "import time\n",
    "import pyautogui\n",
    "\n",
    "class TestHandGestureApp(unittest.TestCase):\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        # Start the GUI application\n",
    "        cls.app_process = subprocess.Popen(['python', 'gui_app.py'])  # Replace with the appropriate command to start your GUI application\n",
    "        time.sleep(5)  # Wait for the application to start (adjust the delay as needed)\n",
    "\n",
    "    @classmethod\n",
    "    def tearDownClass(cls):\n",
    "        # Terminate the GUI application\n",
    "        cls.app_process.terminate()\n",
    "        cls.app_process.wait()\n",
    "\n",
    "    def test_hand_gesture_detection(self):\n",
    "        # Click on the input box and enter a sample input\n",
    "        input_box_loc = pyautogui.locateOnScreen('input_box.png')  # Replace with the appropriate image of the input box\n",
    "        self.assertIsNotNone(input_box_loc, \"Input box not found\")\n",
    "        pyautogui.click(input_box_loc)\n",
    "        pyautogui.write(\"sample input\")\n",
    "\n",
    "        # Click on the Detect button\n",
    "        detect_button_loc = pyautogui.locateOnScreen('detect_button.png')  # Replace with the appropriate image of the Detect button\n",
    "        self.assertIsNotNone(detect_button_loc, \"Detect button not found\")\n",
    "        pyautogui.click(detect_button_loc)\n",
    "\n",
    "        # Wait for the detection result\n",
    "        result_loc = pyautogui.locateOnScreen('result.png')  # Replace with the appropriate image of the detection result\n",
    "        self.assertIsNotNone(result_loc, \"Detection result not found\")\n",
    "\n",
    "        # Assert that the detection result is displayed correctly\n",
    "        result_text = pyautogui.screenshot(region=result_loc)\n",
    "        expected_text = \"Detected gesture: sample gesture\"\n",
    "        self.assertIn(expected_text, result_text, \"Detection result is incorrect\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccfcdf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"gui_app.py\", line 3, in <module>\n",
      "    import mediapipe as mp\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/mediapipe/__init__.py\", line 17, in <module>\n",
      "    import mediapipe.python.solutions as solutions\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/mediapipe/python/solutions/__init__.py\", line 17, in <module>\n",
      "    import mediapipe.python.solutions.drawing_styles\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/mediapipe/python/solutions/drawing_styles.py\", line 20, in <module>\n",
      "    from mediapipe.python.solutions.drawing_utils import DrawingSpec\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/mediapipe/python/solutions/drawing_utils.py\", line 22, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/matplotlib/pyplot.py\", line 2336, in <module>\n",
      "    switch_backend(rcParams[\"backend\"])\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/matplotlib/pyplot.py\", line 276, in switch_backend\n",
      "    class backend_mod(matplotlib.backend_bases._Backend):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/matplotlib/pyplot.py\", line 277, in backend_mod\n",
      "    locals().update(vars(importlib.import_module(backend_name)))\n",
      "  File \"/opt/anaconda3/lib/python3.8/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "ModuleNotFoundError: No module named 'matplotlib_inline'\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Detection result not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     result_text \u001b[38;5;241m=\u001b[39m pyautogui\u001b[38;5;241m.\u001b[39mscreenshot(region\u001b[38;5;241m=\u001b[39m(result_center[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m100\u001b[39m, result_center[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m20\u001b[39m))\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m result_text \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected gesture: sample gesture\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetection result is incorrect\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 38\u001b[0m \u001b[43mtest_detect_gestures_app\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mtest_detect_gestures_app\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Assert that the detection result is displayed correctly\u001b[39;00m\n\u001b[1;32m     32\u001b[0m result_location \u001b[38;5;241m=\u001b[39m pyautogui\u001b[38;5;241m.\u001b[39mlocateOnScreen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m result_location \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetection result not found\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m result_center \u001b[38;5;241m=\u001b[39m pyautogui\u001b[38;5;241m.\u001b[39mcenter(result_location)\n\u001b[1;32m     35\u001b[0m result_text \u001b[38;5;241m=\u001b[39m pyautogui\u001b[38;5;241m.\u001b[39mscreenshot(region\u001b[38;5;241m=\u001b[39m(result_center[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m100\u001b[39m, result_center[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m20\u001b[39m))\u001b[38;5;241m.\u001b[39mtext\n",
      "\u001b[0;31mAssertionError\u001b[0m: Detection result not found"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "import time\n",
    "import unittest\n",
    "import subprocess\n",
    "\n",
    "# Define a test for the Detect Gestures App\n",
    "def test_detect_gestures_app():\n",
    "    # Launch the Detect Gestures App\n",
    "    # Replace this with the code to launch your Python GUI application\n",
    "    app_process = subprocess.Popen(['python', 'gui_app.py'])  # Replace with the appropriate command to start your GUI application\n",
    "    time.sleep(5)  # Wait for the application to start (adjust the delay as needed)\n",
    "    # Wait for the app to load\n",
    "    #time.sleep(2)  # Adjust the delay as needed\n",
    "    \n",
    "    # Find the input box and enter a sample input\n",
    "    input_box_location = pyautogui.locateOnScreen('input_box.png')\n",
    "    if input_box_location is not None:\n",
    "        input_box_center = pyautogui.center(input_box_location)\n",
    "        pyautogui.click(input_box_center)\n",
    "        pyautogui.typewrite('sample input')\n",
    "\n",
    "    # Find the Detect button and click it\n",
    "    detect_button_location = pyautogui.locateOnScreen('detect_button.png')\n",
    "    if detect_button_location is not None:\n",
    "        detect_button_center = pyautogui.center(detect_button_location)\n",
    "        pyautogui.click(detect_button_center)\n",
    "\n",
    "    # Wait for the detection result\n",
    "    time.sleep(2)  # Adjust the delay as needed\n",
    "    \n",
    "    # Assert that the detection result is displayed correctly\n",
    "    result_location = pyautogui.locateOnScreen('result.png')\n",
    "    assert result_location is not None, \"Detection result not found\"\n",
    "    result_center = pyautogui.center(result_location)\n",
    "    result_text = pyautogui.screenshot(region=(result_center[0] - 100, result_center[1] - 10, 200, 20)).text\n",
    "    assert result_text == \"Detected gesture: sample gesture\", \"Detection result is incorrect\"\n",
    "\n",
    "test_detect_gestures_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6098207e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib_inline in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (0.1.6)\n",
      "Requirement already satisfied: traitlets in /opt/anaconda3/envs/env_tensorflow/lib/python3.9/site-packages (from matplotlib_inline) (5.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib_inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "763e5103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "categories = ['Passed', 'Failed', 'Error']\n",
    "values = [4, 1, 0]\n",
    "\n",
    "# Create a bar plot\n",
    "plt.bar(categories, values)\n",
    "\n",
    "# Add labels to the bars\n",
    "for i, value in enumerate(values):\n",
    "    plt.text(i, value + 0.1, str(value), ha='center')\n",
    "\n",
    "# Set plot title and axis labels\n",
    "plt.title('Test Results')\n",
    "plt.xlabel('Test Status')\n",
    "plt.ylabel('Number of Tests')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c95a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
